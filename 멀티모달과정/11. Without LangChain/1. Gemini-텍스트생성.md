
Without LangChain 학습 GitHub
https://github.com/venture21/without-langchain


원래는 Gemini나 Open AI를 사용하려고 하면 해당 사이트의 라이브러리에 들어가서 하나하나 학습을 한 후 사용해야 했다.
https://ai.google.dev/gemini-api/docs/text-generation?hl=ko

https://platform.openai.com/docs/overview


그런데 랭체인이라는 옷을 입힘으로써 자동으로 특정 생성형 AI의 기능을 통일된 코드로 보다 손 쉽게 사용할 수 있게 되었다.

이번에는 LangChain을 사용하지 않고 직접 사용하는 방법에 대해 알아볼 것이다.






# 사전 준비


1. 클론(clone)하기

```
git clone https://github.com/venture21/without-langchain.git
```

2. 가상환경 만들기

```
(base) C:\Users\SBA\github\without-langchain>conda create -n without python=3.11
```

3. 가상환경 들어가기

```
(base) C:\Users\SBA\github\without-langchain>conda activate without
```

4. .env 파일 생성
```
GOOGLE_API_KEY=AIzaSyCtfgpQv03W2p4esoyVsk6Guv-wBc3B4Dg
```

5. google-genai와 python-dotenv 러이브러리 설치
```
!pip install google-genai python-dotenv
```

6. .env파일 로드
``` python
from dotenv import load_dotenv

# .env 파일 로드
load_dotenv()
```

7. GOOGLE_API_KEY값을 api_key변수에 대입
``` python
import os
  
api_key = os.getenv("GOOGLE_API_KEY")
```







# 텍스트 생성

클라이언트(client) 생성 및 답변 요청 해보기

``` python
from google import genai

  

# import google.generativeai as genai

  

# 클라이언트 인스턴스 생성

client = genai.Client(api_key=api_key)

  

# 모델을 지정하고 컨텐츠의 답변을 요청

response = client.models.generate_content(

    # vertexai=False,

    model="gemini-2.5-flash",

    contents="대한민국의 수도는 어디인가요?",

)

print(response.text)
```









# 시스템 안내 및 기타 구성


response(응답 내용)는 다음과 같이 생겼다.

![[Pasted image 20250811131428.png]]

여기서
1. **candidates_token_count**는 대답을 하는데 10개의 토큰이 사용되었다는 뜻
2. **prompt_token_count**는 입력을 받는데 10개의 토큰이 사용되었다는 뜻
3. **thoughts_token_count**는 생각을 하는데 31개의 토큰이 사용되었다는 뜻
4. **total_token_count**는 총합적으로 51개의 토큰이 사용되었다는 뜻





![[Pasted image 20250811132431.png]]

응답에 대한 정보(콘텐츠)에 대해서 이런식으로 원하는 정보만을 뽑아서 출력시킬 수 있다.



![[Pasted image 20250811132505.png]]

토큰과 관련된 정보(usage_metadata)에 대해서도 원하는 정보만을 뽑아서 출력시킬 수 있다.








# 시스템 인스트럭션 설정

GenerateContentConfig()로 시스템 인스트럭션을 설정

```python
from google import genai

from google.genai import types

  

client = genai.Client()

  

# Google Gemini 모델과 직접 상호작용하여 콘텐츠를 생성하는 데 사용되는 핵심 함수

response = client.models.generate_content(

    model="gemini-2.5-flash",

    config=types.GenerateContentConfig(

        # 시스템 인스트럭션

        system_instruction="당신은 고양이이고, 이름은 야옹이입니다."

    ),

    contents="안녕",

)

  

print(response.text)
```

**types.GenerateContentConfig()** 메서드를 통해서 시스템 인스트럭션 설정 할 수 있다.



실행 결과
![[Pasted image 20250811165512.png]]










# temperature 설정

GenerateContentConfig()로 **temperature** 설정

```python
from google import genai

from google.genai import types

  

client = genai.Client()

  

response = client.models.generate_content(

    model="gemini-2.5-flash",

    contents=["Explain how AI works"],

    config=types.GenerateContentConfig(temperature=0.1),

)

print(response.text)
```

**types.GenerateContentConfig()** 메서드를 통해서 temperature 설정을 할 수 있다.

### Temperature란?

`언어 생성 모델에서 생성된 텍스트의 다양성(degree of diversity)을 조절하는 하이퍼파라미터`입니다. 즉, _temperature 값이 높을수록 모델이 생성하는 문장이 더 다양해지고, 값이 낮을수록 더 일관성 있는 문장이 생성_됩니다.

예를 들어, temperature 값이 높은 경우, 모델은 다양한 선택지를 고려하여 텍스트를 생성합니다. 이는 모델이 더 많은 무작위성(randomness)을 가지게 하며, 때로는 예상치 못한 문장을 생성할 수도 있습니다. 반면에, temperature 값이 낮은 경우, 모델은 가능한 선택지 중에서 가장 확률이 높은 것을 선택하게 됩니다. 이는 보다 일관성 있는 텍스트를 생성할 수 있게 하지만, 다소 지루하거나 예상 가능한 결과를 만들 수도 있습니다.






# 멀티 모달 입력

 1. 이미지를 입력할 경우
 
```python
from google.genai import types

  

# 이미지 파일을 읽어와서 바이너리 데이터로 변환

with open("organ.jpg", "rb") as f:

    image_bytes = f.read()

  
  

response = client.models.generate_content(

    model="gemini-2.5-flash",

    contents=[

        # 바이너리 타입의 이미지

        types.Part.from_bytes(

            # 바이너리로 읽은 데이터를 첨부하기

            data=image_bytes,

            mime_type="image/jpeg",

        ),

        # text 타입의 프로젝트

        "이 악기에 대해 설명해줘",

    ],

)

  

print("=== 응답 ===")

print(response.text)

print("\n=== 토큰 사용량 ===")

print(f"입력 토큰: {response.usage_metadata.prompt_token_count}")

print(f"출력 토큰: {response.usage_metadata.candidates_token_count}")

print(f"총 토큰: {response.usage_metadata.total_token_count}")
```

위와 같이 이미지를 읽어들이는 경우에는 바이너리 형태로 읽어들이도록 설정해야한다. 바이너리란 Gemini 생성형 AI가 이해할 수 있도록 이미지의 데이터를 한 줄로 변환시키는 것이다.

### `rb`의 역할

- **`r`** 은 파일을 **읽기(read)** 모드로 연다는 뜻입니다.
    
- **`b`** 는 파일을 **바이너리(binary)** 모드로 연다는 뜻입니다.
    

이 두 가지를 합친 `"rb"` 모드는 이미지나 동영상처럼 텍스트가 아닌 데이터를 **있는 그대로의 바이트(byte) 배열**로 읽어올 때 사용합니다. 만약 "r" (텍스트 모드)로 열면 파일 내용을 텍스트로 인식하려고 해서 오류가 발생할 수 있습니다.
    
- `f.read()`: `read()` 메서드는 열려 있는 파일 객체 `f`의 내용을 처음부터 끝까지 모두 읽어와서 반환합니다.
    

결과적으로, `image_bytes` 변수에는 `organ.jpg` 파일의 모든 데이터가 컴퓨터가 직접 이해할 수 있는 **바이너리 형태**로 담기게 됩니다. 이렇게 읽어온 바이너리 데이터는 Gemini API에 이미지 정보로 전달될 수 있습니다.

### `types.Part.from_bytes()`의 역할

Gemini API는 텍스트, 이미지, 오디오 등 여러 가지 형식의 데이터를 한 번에 처리할 수 있는 **멀티모달(multimodal)** 모델입니다. 따라서 API에 데이터를 보낼 때는 각 데이터가 어떤 형식인지 명확하게 알려줘야 합니다.

`types.Part.from_bytes()`는 바로 이 역할을 하는 "포장지"입니다.

1. **데이터의 본체(data)**: `data=image_bytes`는 우리가 읽어온 이미지의 바이너리 데이터 그 자체입니다.
    
2. **데이터의 종류(mime_type)**: `mime_type="image/jpeg"`는 이 바이너리 데이터가 **JPEG 형식의 이미지**라는 것을 API에게 알려주는 일종의 꼬리표입니다.
    

만약 `image_bytes`만 보낸다면, API 입장에서는 이것이 이미지인지, 오디오 파일인지, 아니면 알 수 없는 데이터인지 구분할 방법이 없습니다.

따라서 `types.Part.from_bytes()` 코드는 `image_bytes`를 단순히 보내는 것이 아니라, **"이 데이터는 JPEG 이미지입니다"**라는 정보를 함께 묶어서 API에 전달하는 필수적인 과정입니다.






2. 이미지를 읽는 다른 방법

```python
from PIL import Image

from google import genai

from google.genai import types

import io

  

client = genai.Client()

  

image = Image.open("organ.jpg")

  

# Convert image to bytes

img_byte_arr = io.BytesIO()

image.save(img_byte_arr, format="JPEG")

img_byte_arr = img_byte_arr.getvalue()

  

response = client.models.generate_content(

    model="gemini-2.5-flash",

    contents=[

        types.Content(

            role="user",

            parts=[

                types.Part(text="이 악기에 대해 설명해줘"),

                types.Part(

                    inline_data=types.Blob(mime_type="image/jpeg", data=img_byte_arr)

                ),

            ],

        )

    ],

)

print(response.text)
```



### 1. 이미지 데이터를 바이너리로 변환하는 과정

`PIL`로 불러온 이미지 객체를 API에 보낼 수 있는 순수한 바이너리 데이터로 바꾸는 역할

- `img_byte_arr = io.BytesIO()`
    
    - **`io.BytesIO()`**는 메모리(RAM)에 생성되는 특별한 "임시 파일"이라고 생각하면 이해하기 쉽습니다. 실제 컴퓨터의 디스크에 파일을 만드는 것이 아니라, 메모리 공간에 데이터를 담을 수 있는 빈 상자를 만드는 것입니다.
        
- `image.save(img_byte_arr, format="JPEG")`
    
    - `image` 객체는 `PIL` 라이브러리로 열린 이미지 자체입니다. 이 코드는 `image` 객체의 내용을 `JPEG` 형식으로 변환하여 위에서 만든 메모리 속 상자(`img_byte_arr`)에 저장합니다. 이제 상자 안에는 이미지의 바이너리 데이터가 담겨 있습니다. 이때 중요한 점은, `image.save()` 메서드를 호출할 때, `PIL` 라이브러리가 `format="JPEG"` 형식의 **바이트(byte) 데이터로 자동으로 변환**한다는 것 입니다. 그냥 save메서드의 작동 방식이 그렇다고 생각하면 됩니다.
        
- `img_byte_arr = img_byte_arr.getvalue()`
    
    - 이 코드는 상자(`io.BytesIO` 객체) 안에 들어 있는 내용물, 즉 이미지의 **순수한 바이너리 데이터(bytes)**만을 꺼내 `img_byte_arr` 변수에 다시 할당합니다. 이 데이터가 바로 Gemini API에 전달될 준비가 된 최종 형태입니다.
        

---

### 2. 변환된 데이터를 API에 전달하는 과정

이 코드는 위에서 준비한 바이너리 데이터를 Gemini가 인식할 수 있도록 "포장"하는 과정입니다.

- `types.Part(...)`
    
    - 이것은 Gemini API가 받는 **하나의 데이터 덩어리**를 나타내는 객체입니다. 텍스트이든, 이미지이든, 모든 데이터는 이 `Part` 객체에 담겨야 합니다.
        
- `inline_data=types.Blob(mime_type="image/jpeg", data=img_byte_arr)`
    
    - `inline_data`는 `Part` 객체 안에 이미지와 같은 비(非)텍스트 데이터를 포함할 때 사용합니다.
        
    - **`types.Blob`**: 바이너리 데이터를 담기 위해 특별히 설계된 객체입니다. 이 객체는 두 가지 정보를 담습니다.
        
        - **`mime_type="image/jpeg"`**: "내가 지금 보내는 데이터는 JPEG 형식의 이미지야"라고 API에 알려주는 **꼬리표**입니다. 이 정보가 없으면 API는 이 데이터가 무엇인지 알 수 없습니다.
            
        - **`data=img_byte_arr`**: 위에서 준비한 이미지의 **실제 바이너리 데이터**를 담는 부분입니다.
            

요약하자면, 위쪽의 세 줄은 **재료(바이너리 데이터)를 준비**하는 과정이고, 마지막 한 줄은 그 재료를 API가 알아볼 수 있도록 **라벨이 붙은 상자에 담는 과정**이라고 할 수 있습니다.

이 두 번째 방식은 **더 명시적이고 자세한** 방법으로, API에 전달하는 모든 구성요소를 직접 제어할 수 있습니다. 예를 들어, `role="user"`를 명시해 이 내용이 사용자의 입력임을 분명히 밝히는 등의 작업이 가능합니다.








# 스트리밍 응답

한 번에 출력하는 것이 아니라 중간 중간에 끊어서 출력
```python
from google import genai

  

client = genai.Client()

  

response = client.models.generate_content_stream(

    model="gemini-2.5-flash", contents=["인공지능에 대해 2문장으로 설명해줘"]

)

for chunk in response:

    print(chunk.text, end="")
```

chunk: 여러 개의 토큰으로 이루어지는 한 단위. 즉, 전체 문단은 여러 개의 chunk로 이루어져 있다.

### generate_content_stream의 반환 값에 대한 주의점

generate_content_stream()메서드의 결과값은 list형태가 아니라 stream이다.


### **List (배열)** 방식

- **동작 방식**: 모델의 응답 전체가 완성될 때까지 기다린 후, 한 번에 **하나의 덩어리(List)**로 받습니다.
    
- **사용 메서드**: `client.models.generate_content()`
    
- **비유**: 영화 파일을 모두 **다운로드 완료**한 뒤에 재생하는 것과 같습니다.
    

### **Stream (스트림)** 방식

- **동작 방식**: 응답이 생성되는 대로 **조금씩(chunk)** 실시간으로 받습니다.
    
- **사용 메서드**: `client.models.generate_content_stream()`
    
- **비유**: 넷플릭스처럼 다운로드 없이 **바로 재생**하며 보는 것과 같습니다.
    

---

### **핵심 차이점**

스트림 방식은 `for chunk in response:` 같은 반복문을 사용해 데이터를 실시간으로 처리할 수 있기 때문에, **응답이 완료될 때까지 기다릴 필요 없이 더 빠른 사용자 경험**을 제공합니다.









# 멀티턴 대화 (채팅)

채팅 형태로 만들기

```python
from google import genai

  

client = genai.Client()

chat = client.chats.create(model="gemini-2.5-flash")

  

response = chat.send_message("나는 우리 집에 2마리 강아지가 있다.")

print(response.text)

  

response = chat.send_message(

    "그렇다면 우리집에 있는 동물의 발의 수는 어떻게 되는지 간단히 답해봐?"

)

print(response.text)

  

for message in chat.get_history():

    print(f"role - {message.role}", end=": ")

    print(message.parts[0].text)
```




![[Pasted image 20250811143227.png]]

