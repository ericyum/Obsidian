
# 임베딩 생성

```python
!pip install numpy scikit-learn
```

```python
from google import genai

  

client = genai.Client()

  

result = client.models.embed_content(

        model="gemini-embedding-001",

        contents="What is the meaning of life?")

  

print(result.embeddings)
```

![[Pasted image 20250812143548.png]]


---

### 코드 분석

#### 1. 라이브러리 및 클라이언트 초기화


```python
from google import genai

client = genai.Client()
```

- `from google import genai`: Google Generative AI API를 사용하기 위한 라이브러리를 가져옵니다.
    
- `client = genai.Client()`: API 호출을 위한 클라이언트 객체를 생성합니다.
    

#### 2. 임베딩 생성 API 호출


```python
result = client.models.embed_content(
    model="gemini-embedding-001",
    contents="What is the meaning of life?")
```

이 부분이 텍스트를 임베딩으로 변환하는 핵심 코드입니다.

- `client.models.embed_content()`: 텍스트를 입력받아 임베딩을 생성하는 함수를 호출합니다.
    
- `model="gemini-embedding-001"`: 사용할 임베딩 모델을 지정합니다. 이 모델은 텍스트의 의미를 잘 파악하여 고차원 벡터로 변환하는 데 특화되어 있습니다.
    
- `contents="What is the meaning of life?"`: 임베딩을 생성할 텍스트입니다. "인생의 의미는 무엇인가요?"라는 질문을 모델에 전달합니다.
    

#### 3. 결과 출력


```python
print(result.embeddings)
```

- `result.embeddings`: `embed_content` 함수의 반환 객체인 `result`에는 임베딩 정보가 담겨 있습니다. 이 코드는 그중 `embeddings` 속성에 있는 실제 임베딩 값들을 출력합니다.
    
- **임베딩(Embedding)**이란, 텍스트를 AI 모델이 이해할 수 있는 숫자 벡터(고차원 배열)로 변환한 것입니다. 의미적으로 비슷한 텍스트는 임베딩 벡터 공간에서 서로 가깝게 위치하게 됩니다.









```python
from google import genai

  

client = genai.Client()

  

result = client.models.embed_content(

        model="gemini-embedding-001",

        contents= [

            "What is the meaning of life?",

            "What is the purpose of existence?",

            "How do I bake a cake?"

        ])

  

for embedding in result.embeddings:

    print(embedding)
```

![[Pasted image 20250812143624.png]]

```python
len(result.embeddings[0].values)
```

![[Pasted image 20250812143646.png]]











다음 예시에서는 SEMANTIC_SIMILARITY를 사용하여 텍스트 문자열의 의미가 얼마나 유사한지 확인하는 방법을 보여줍니다.

```python
from google import genai

from google.genai import types

import numpy as np

from sklearn.metrics.pairwise import cosine_similarity

  

client = genai.Client()

  

texts = [

    "What is the meaning of life?",

    "What is the purpose of existence?",

    "How do I bake a cake?"]

  

result = [

    np.array(e.values) for e in client.models.embed_content(

        model="gemini-embedding-001",

        contents=texts,

        config=types.EmbedContentConfig(task_type="SEMANTIC_SIMILARITY")).embeddings

]

  

# Calculate cosine similarity. Higher scores = greater semantic similarity.

  

embeddings_matrix = np.array(result)

similarity_matrix = cosine_similarity(embeddings_matrix)

  

for i, text1 in enumerate(texts):

    for j in range(i + 1, len(texts)):

        text2 = texts[j]

        similarity = similarity_matrix[i, j]

        print(f"Similarity between '{text1}' and '{text2}': {similarity:.4f}")
```

![[Pasted image 20250812143714.png]]











# 임베딩 벡터 크기 제어


```python
from google import genai

from google.genai import types

  

client = genai.Client()

  

result = client.models.embed_content(

    model="gemini-embedding-001",

    contents="What is the meaning of life?",

    config=types.EmbedContentConfig(output_dimensionality=768)

)

  

[embedding_obj] = result.embeddings

embedding_length = len(embedding_obj.values)

  

print(f"Length of embedding: {embedding_length}")
```

![[Pasted image 20250812143740.png]]











3072 차원 임베딩은 정규화됩니다. 정규화된 임베딩은 크기가 아닌 벡터 방향을 비교하여 더 정확한 의미 유사성을 생성합니다. 768, 1536을 비롯한 다른 차원의 경우 다음과 같이 임베딩을 정규화해야 합니다.

```python
import numpy as np

from numpy.linalg import norm

  

embedding_values_np = np.array(embedding_obj.values)

normed_embedding = embedding_values_np / np.linalg.norm(embedding_values_np)

  

print(f"Normed embedding length: {len(normed_embedding)}")

print(f"Norm of normed embedding: {np.linalg.norm(normed_embedding):.6f}") # Should be very close to 1
```

![[Pasted image 20250812143801.png]]
