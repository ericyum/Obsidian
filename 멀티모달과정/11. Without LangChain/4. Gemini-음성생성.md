
# 단일 화자 텍스트 음성 변환

```python
from google import genai

from google.genai import types

import wave

  

# Set up the wave file to save the output:

def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):

   with wave.open(filename, "wb") as wf:

      wf.setnchannels(channels)

      wf.setsampwidth(sample_width)

      wf.setframerate(rate)

      wf.writeframes(pcm)

  

client = genai.Client()

  

response = client.models.generate_content(

   model="gemini-2.5-flash-preview-tts",

   #contents="Say cheerfully: Have a wonderful day!",

   contents="밝은 목소리로: 좋은 아침입니다!",

   config=types.GenerateContentConfig(

      response_modalities=["AUDIO"],

      speech_config=types.SpeechConfig(

         voice_config=types.VoiceConfig(

            prebuilt_voice_config=types.PrebuiltVoiceConfig(

               voice_name='Kore',

            )

         )

      ),

   )

)

  

data = response.candidates[0].content.parts[0].inline_data.data

  

file_name='kor-good-morning.wav'

wave_file(file_name, data) # Saves the file to current directory
```

### 1. WAV 파일 저장 헬퍼 함수


```Python
def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):
    with wave.open(filename, "wb") as wf:
      wf.setnchannels(channels)
      wf.setsampwidth(sample_width)
      wf.setframerate(rate)
      wf.writeframes(pcm)
```

- **역할**: 이 함수는 실제 API 통신과 관계없이, `wave` 라이브러리를 사용해 받은 음성 데이터를 표준 `.wav` 파일 형식으로 저장하는 역할을 합니다.
    
- **`pcm`**: API에서 받은 **실제 음성 데이터(바이너리)**가 이 매개변수로 전달됩니다.
    
- 나머지 매개변수들(`channels`, `rate` 등)은 `.wav` 파일이 올바르게 재생될 수 있도록 음성 데이터의 기술적인 정보(채널 수, 샘플링 속도 등)를 설정하는 부분입니다.
    

### 2. API 호출: 텍스트를 음성으로 변환 요청


```Python
response = client.models.generate_content(
   model="gemini-2.5-flash-preview-tts",
   contents="밝은 목소리로: 좋은 아침입니다!",
   config=types.GenerateContentConfig(
       response_modalities=["AUDIO"],
       speech_config=types.SpeechConfig(
           voice_config=types.VoiceConfig(
               prebuilt_voice_config=types.PrebuiltVoiceConfig(
                   voice_name='Kore',
               )
           )
       ),
    )
)
```

- **`model="gemini-2.5-flash-preview-tts"`**: 텍스트를 음성으로 변환하는 데 특화된 모델을 지정합니다.
    
- **`contents="..."`**: 음성으로 변환할 텍스트를 제공합니다.
    
- **`config=...`**: 음성 생성에 필요한 세부 설정을 담는 객체입니다.
    
    - **`response_modalities=["AUDIO"]`**: **응답의 형태를 '오디오'로 받겠다**고 명시하는 매우 중요한 설정입니다. 이 설정이 없으면 텍스트 응답만 받게 됩니다.
        
    - **`speech_config`**: 음성 관련 설정을 담는 컨테이너입니다.
        
    - **`voice_name='Kore'`**: 사용할 음성의 언어와 종류를 지정합니다. 이 경우, **한국어 음성**을 선택합니다.
        

### 3. 응답 데이터 추출 및 파일 저장


```Python
data = response.candidates[0].content.parts[0].inline_data.data

file_name='kor-good-morning.wav'
wave_file(file_name, data)
```

- **`data = ...`**: API 응답 객체(`response`)에서 실제 음성 데이터(`data`)를 추출하는 과정입니다. 복잡해 보이지만, **"응답 객체에 포함된 오디오 바이너리 데이터를 꺼내달라"**는 의미입니다.
    
- **`file_name='kor-good-morning.wav'`**: 저장할 파일의 이름을 지정합니다.
    
- **`wave_file(file_name, data)`**: 첫 번째 부분에서 정의한 `wave_file` 함수를 호출하여, 추출한 음성 데이터를 `kor-good-morning.wav`라는 이름의 `.wav` 파일로 저장합니다.










```python
contents_prompt=""" 뉴스 앵커가 다음 본문을 읽는다 : "이제는 동남아 국가보다 한국이 더 더운 것 같다."

태국 방콕 등지에서 10여 년간 살다가 지난해 한국에 들어온 직장인 박모 씨의 말이다. 박 씨는 "20대 초반 한국에 살 때만 해도 여름이 이렇게 덥지는 않았던 것 같은데 올해는 밖에 나가기가 무서울 정도로 덥다"고 덧붙였다.

"""

  

from google import genai

from google.genai import types

import wave

  

# Set up the wave file to save the output:

def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):

   with wave.open(filename, "wb") as wf:

      wf.setnchannels(channels)

      wf.setsampwidth(sample_width)

      wf.setframerate(rate)

      wf.writeframes(pcm)

  

client = genai.Client()

  

response = client.models.generate_content(

   model="gemini-2.5-flash-preview-tts",

   #contents="Say cheerfully: Have a wonderful day!",

   contents=contents_prompt,

   config=types.GenerateContentConfig(

      response_modalities=["AUDIO"],

      speech_config=types.SpeechConfig(

         voice_config=types.VoiceConfig(

            prebuilt_voice_config=types.PrebuiltVoiceConfig(

               voice_name='Kore',

            )

         )

      ),

   )

)

  

data = response.candidates[0].content.parts[0].inline_data.data

  

file_name='kor-weather-news.wav'

wave_file(file_name, data) # Saves the file to current directory
```


#### 1. 변환할 텍스트 정의


```Python
contents_prompt=""" 뉴스 앵커가 다음 본문을 읽는다 : "이제는 동남아 국가보다 한국이 더 더운 것 같다."
태국 방콕 등지에서 10여 년간 살다가 지난해 한국에 들어온 직장인 박모 씨의 말이다. 박 씨는 "20대 초반 한국에 살 때만 해도 여름이 이렇게 덥지는 않았던 것 같은데 올해는 밖에 나가기가 무서울 정도로 덥다"고 덧붙였다.
"""
```

- **역할**: 음성으로 변환할 뉴스 기사 본문 텍스트를 `contents_prompt`라는 변수에 저장합니다. 이렇게 긴 텍스트는 가독성을 위해 변수로 따로 정의해 사용하는 것이 일반적입니다.
    

#### 2. 음성 변환 요청 및 설정


```Python
response = client.models.generate_content(
   model="gemini-2.5-flash-preview-tts",
   contents=contents_prompt,
   config=types.GenerateContentConfig(
       response_modalities=["AUDIO"],
       speech_config=types.SpeechConfig(
           voice_config=types.VoiceConfig(
               prebuilt_voice_config=types.PrebuiltVoiceConfig(
                   voice_name='Kore',
               )
           )
       ),
    )
)
```

- **`contents=contents_prompt`**: 이전 코드와 달리, 변환할 텍스트를 `contents_prompt` 변수에서 가져옵니다.
    
- **나머지 설정**: `model` 지정, `response_modalities`를 **"AUDIO"**로 설정, **`Kore` 음성**을 선택하는 등의 과정은 이전과 동일합니다. 이는 텍스트의 내용과 관계없이 오디오를 생성하기 위한 공통 설정입니다.
    

#### 3. 음성 데이터 추출 및 파일 저장


```Python
data = response.candidates[0].content.parts[0].inline_data.data

file_name='kor-weather-news.wav'
wave_file(file_name, data)
```

- **`data = ...`**: API 응답에서 변환된 오디오의 바이너리 데이터를 추출합니다.
    
- **`file_name='kor-weather-news.wav'`**: 출력될 WAV 파일의 이름이 `kor-weather-news.wav`로 지정되었습니다.
    
- **`wave_file(...)`**: 추출한 오디오 데이터를 로컬 파일로 저장합니다.









# 복수 화자 텍스트 음성 변환

```python
from google import genai

from google.genai import types

import wave

  

# Set up the wave file to save the output:

def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):

   with wave.open(filename, "wb") as wf:

      wf.setnchannels(channels)

      wf.setsampwidth(sample_width)

      wf.setframerate(rate)

      wf.writeframes(pcm)

  

client = genai.Client()

  

prompt = """TTS the following conversation between Joe and Jane:

         Joe: How's it going today Jane?

         Jane: Not too bad, how about you?"""

  

response = client.models.generate_content(

   model="gemini-2.5-flash-preview-tts",

   contents=prompt,

   config=types.GenerateContentConfig(

      response_modalities=["AUDIO"],

      speech_config=types.SpeechConfig(

         multi_speaker_voice_config=types.MultiSpeakerVoiceConfig(

            speaker_voice_configs=[

               types.SpeakerVoiceConfig(

                  speaker='Joe',

                  voice_config=types.VoiceConfig(

                     prebuilt_voice_config=types.PrebuiltVoiceConfig(

                        voice_name='Kore',

                     )

                  )

               ),

               types.SpeakerVoiceConfig(

                  speaker='Jane',

                  voice_config=types.VoiceConfig(

                     prebuilt_voice_config=types.PrebuiltVoiceConfig(

                        voice_name='Puck',

                     )

                  )

               ),

            ]

         )

      )

   )

)

  

data = response.candidates[0].content.parts[0].inline_data.data

  

file_name='eng-greetings.wav'

wave_file(file_name, data) # Saves the file to current directory
```

#### 1. 프롬프트 및 파일 저장 설정


```Python
prompt = """TTS the following conversation between Joe and Jane:
        Joe: How's it going today Jane?
        Jane: Not too bad, how about you?"""
...
file_name='eng-greetings.wav'
wave_file(file_name, data)
```

- **`prompt`**: `Joe:`와 `Jane:`이라는 **화자 이름(speaker label)**이 포함된 대화 스크립트입니다. 모델이 이 라벨을 기반으로 각 화자의 대사를 구분합니다.
    
- **`wave_file` 함수 및 파일 저장**: 이전 코드와 동일하게 음성 데이터를 `.wav` 파일로 저장하는 역할을 합니다.
    

#### 2. API 호출: 멀티 스피커 음성 생성 요청


```Python
response = client.models.generate_content(
    model="gemini-2.5-flash-preview-tts",
    contents=prompt,
    config=types.GenerateContentConfig(
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            multi_speaker_voice_config=types.MultiSpeakerVoiceConfig(
                speaker_voice_configs=[
                    types.SpeakerVoiceConfig(
                        speaker='Joe',
                        voice_config=types.VoiceConfig(
                            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                voice_name='Kore',
                            )
                        )
                    ),
                    types.SpeakerVoiceConfig(
                        speaker='Jane',
                        voice_config=types.VoiceConfig(
                            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                voice_name='Puck',
                            )
                        )
                    ),
                ]
            )
        )
    )
)
```

- **`model`**: 이전과 동일한 음성 생성 모델을 사용합니다.
    
- **`response_modalities=["AUDIO"]`**: 음성 응답을 요청하는 설정입니다.
    
- **`multi_speaker_voice_config=types.MultiSpeakerVoiceConfig(...)`**: 이 부분이 핵심입니다. 모델에게 **여러 화자의 음성을 생성**하도록 지시하는 설정입니다.
    
- **`speaker_voice_configs=[...]`**: 각 화자에 대한 세부 설정이 담긴 리스트입니다.
    
- **`types.SpeakerVoiceConfig(speaker='Joe', ...)`**: 첫 번째 화자인 `Joe`에 대한 설정입니다.
    
    - **`speaker='Joe'`**: 프롬프트에 있는 `Joe:`라는 라벨과 일치하는 화자를 지정합니다.
        
    - **`voice_name='Kore'`**: `Joe`의 대사는 `Kore`라는 이름의 목소리로 생성됩니다.
        
- **`types.SpeakerVoiceConfig(speaker='Jane', ...)`**: 두 번째 화자인 `Jane`에 대한 설정입니다.
    
    - **`speaker='Jane'`**: 프롬프트에 있는 `Jane:` 라벨과 일치하는 화자를 지정합니다.
        
    - **`voice_name='Puck'`**: `Jane`의 대사는 `Puck`이라는 이름의 목소리로 생성됩니다.
        

#### 3. 응답 데이터 추출 및 파일 저장


```Python
data = response.candidates[0].content.parts[0].inline_data.data

file_name='eng-greetings.wav'
wave_file(file_name, data)
```

- **`data = ...`**: `response` 객체에서 **하나로 합쳐진** 최종 오디오 데이터를 추출합니다.
    
- **`wave_file(file_name, data)`**: 추출한 오디오 데이터를 `.wav` 파일로 저장합니다.
    

요약하면, 이 코드는 **프롬프트에 있는 화자 이름과 설정에서 지정한 목소리를 연결**하여, 한 파일 안에 여러 화자의 대화가 포함된 음성을 생성하는 방법을 보여줍니다.