
# 이미지 생성(텍스트 이미지 변환)

```python
from google import genai

from google.genai import types

from PIL import Image

from io import BytesIO

  

client = genai.Client()

  

response = client.models.generate_images(

    model="imagen-4.0-generate-preview-06-06",

    prompt="Cute robot holding a red skateboard",

    config=types.GenerateImagesConfig(

        number_of_images=4,

    ),

)

for generated_image in response.generated_images:

    generated_image.image.show()
```


### 코드 분석

---

```python
from google import genai
from google.genai import types
from PIL import Image
from io import BytesIO
```

이 부분은 필요한 라이브러리를 가져오는 코드입니다.

- `from google import genai`: Google Generative AI 라이브러리인 `genai`를 가져옵니다. 이 라이브러리를 사용해 Google AI 모델에 접근할 수 있습니다.
    
- `from google.genai import types`: API 호출 시 사용되는 다양한 데이터 타입을 정의하는 `types` 모듈을 가져옵니다. 뒤에 나오는 `GenerateImagesConfig`와 같은 설정 클래스가 이 모듈에 있습니다.
    
- `from PIL import Image`: Python Imaging Library (PIL)의 `Image` 모듈을 가져옵니다. 생성된 이미지를 화면에 표시하거나 저장할 때 사용됩니다.
    
- `from io import BytesIO`: 인메모리(in-memory) 바이너리 스트림을 다루는 `BytesIO` 모듈을 가져옵니다. 이 코드에서는 생성된 이미지를 바이너리 형태로 받아서 처리할 때 필요할 수 있습니다.
    

```python
client = genai.Client()
```

이 코드는 `genai` 라이브러리를 사용하기 위한 **클라이언트 객체**를 생성합니다. `client` 객체를 통해 이미지 생성과 같은 다양한 API 함수를 호출할 수 있습니다.


```python
response = client.models.generate_images(
    model="imagen-4.0-generate-preview-06-06",
    prompt="Cute robot holding a red skateboard",
    config=types.GenerateImagesConfig(
        number_of_images=4,
    ),
)
```

이 부분이 이미지를 실제로 생성하는 핵심 코드입니다.

- `client.models.generate_images()`: 클라이언트 객체를 통해 이미지 생성 함수를 호출합니다.
    
- `model="imagen-4.0-generate-preview-06-06"`: 사용할 이미지 생성 **모델**을 지정합니다. 여기서는 "imagen-4.0" 모델의 특정 프리뷰 버전을 사용하고 있네요.
    
- `prompt="Cute robot holding a red skateboard"`: 생성하고 싶은 이미지를 **텍스트로 설명(프롬프트)**합니다. "빨간색 스케이트보드를 들고 있는 귀여운 로봇" 이미지를 만들어 달라고 명령하는 것입니다.
    
- `config=types.GenerateImagesConfig(...)`: 이미지 생성에 대한 추가 **설정**을 지정합니다.
    
    - `number_of_images=4`: 하나의 프롬프트로 **4개의 이미지를 생성**하도록 설정합니다.
        


```python
for generated_image in response.generated_images:
    generated_image.image.show()
```

이 코드는 생성된 이미지들을 하나씩 반복해서 화면에 보여줍니다.

- `response.generated_images`: API 호출의 결과로 받은 이미지 목록입니다. `generate_images` 함수는 요청한 개수만큼 이미지를 포함하는 `response` 객체를 반환합니다.
    
- `for generated_image in ...`: 이미지 목록의 각 이미지를 `generated_image`라는 변수로 반복합니다.
    
- `generated_image.image.show()`: PIL 라이브러리의 `show()` 함수를 사용하여 `generated_image` 객체에 포함된 이미지를 별도의 뷰어 창으로 띄워 보여줍니다.









```python
from google import genai

from google.genai import types

from PIL import Image

from io import BytesIO

  

import PIL.Image

  

image = PIL.Image.open("../data/mark.jpg")

  

client = genai.Client()

  

text_input = "Hi, This is a picture of me." "Can you add a dog next to me?"

  

response = client.models.generate_content(

    model="gemini-2.0-flash-preview-image-generation",

    contents=[

        types.Content(

            role="user",

            parts=[

                types.Part(text=text_input),

                types.Part(

                    inline_data=types.Blob(

                        mime_type="image/jpeg",

                        data=open("../data/mark.jpg", "rb").read(),

                    )

                ),

            ],

        )

    ],

    config=types.GenerateContentConfig(response_modalities=["TEXT", "IMAGE"]),

)

  

for part in response.candidates[0].content.parts:

    if part.text is not None:

        print(part.text)

    elif part.inline_data is not None:

        image = Image.open(BytesIO((part.inline_data.data)))

        image.save("../data/mark_result.jpg")

        image.show()
```


### 코드 분석

---

```python
from google import genai
from google.genai import types
from PIL import Image
from io import BytesIO
```

이 부분은 필요한 라이브러리를 가져오는 코드입니다.

- `from google import genai`: Google Generative AI 라이브러리인 `genai`를 가져옵니다. 이 라이브러리를 사용해 Google AI 모델에 접근할 수 있습니다.
    
- `from google.genai import types`: API 호출 시 사용되는 다양한 데이터 타입을 정의하는 `types` 모듈을 가져옵니다. 뒤에 나오는 `GenerateImagesConfig`와 같은 설정 클래스가 이 모듈에 있습니다.
    
- `from PIL import Image`: Python Imaging Library (PIL)의 `Image` 모듈을 가져옵니다. 생성된 이미지를 화면에 표시하거나 저장할 때 사용됩니다.
    
- `from io import BytesIO`: 인메모리(in-memory) 바이너리 스트림을 다루는 `BytesIO` 모듈을 가져옵니다. 이 코드에서는 생성된 이미지를 바이너리 형태로 받아서 처리할 때 필요할 수 있습니다.
    


```python
client = genai.Client()
```

이 코드는 `genai` 라이브러리를 사용하기 위한 **클라이언트 객체**를 생성합니다. `client` 객체를 통해 이미지 생성과 같은 다양한 API 함수를 호출할 수 있습니다.


```python
response = client.models.generate_images(
    model="imagen-4.0-generate-preview-06-06",
    prompt="Cute robot holding a red skateboard",
    config=types.GenerateImagesConfig(
        number_of_images=4,
    ),
)
```

이 부분이 이미지를 실제로 생성하는 핵심 코드입니다.

- `client.models.generate_images()`: 클라이언트 객체를 통해 이미지 생성 함수를 호출합니다.
    
- `model="imagen-4.0-generate-preview-06-06"`: 사용할 이미지 생성 **모델**을 지정합니다. 여기서는 "imagen-4.0" 모델의 특정 프리뷰 버전을 사용하고 있네요.
    
- `prompt="Cute robot holding a red skateboard"`: 생성하고 싶은 이미지를 **텍스트로 설명(프롬프트)**합니다. "빨간색 스케이트보드를 들고 있는 귀여운 로봇" 이미지를 만들어 달라고 명령하는 것입니다.
    
- `config=types.GenerateImagesConfig(...)`: 이미지 생성에 대한 추가 **설정**을 지정합니다.
    
    - `number_of_images=4`: 하나의 프롬프트로 **4개의 이미지를 생성**하도록 설정합니다.
        


```python
for generated_image in response.generated_images:
    generated_image.image.show()
```

이 코드는 생성된 이미지들을 하나씩 반복해서 화면에 보여줍니다.

- `response.generated_images`: API 호출의 결과로 받은 이미지 목록입니다. `generate_images` 함수는 요청한 개수만큼 이미지를 포함하는 `response` 객체를 반환합니다.
    
- `for generated_image in ...`: 이미지 목록의 각 이미지를 `generated_image`라는 변수로 반복합니다.
    
- `generated_image.image.show()`: PIL 라이브러리의 `show()` 함수를 사용하여 `generated_image` 객체에 포함된 이미지를 별도의 뷰어 창으로 띄워 보여줍니다.






```python
# 텍스트와 이미지를 함께 입력받아 새로운 이미지 생성하기

from google import genai

from google.genai import types

from PIL import Image

from io import BytesIO

  

client = genai.Client()

  

# 텍스트 프롬프트와 이미지를 함께 입력

text_prompt = "이미지의 두 사람이 서있는 곳을 해변 배경으로 변경하고, 하늘에 아름다운 노을을 그려주세요"

  

response = client.models.generate_content(

    model="gemini-2.0-flash-preview-image-generation",

    contents=[

        types.Content(

            role="user",

            parts=[

                types.Part(text=text_prompt),

                types.Part(

                    inline_data=types.Blob(

                        mime_type="image/jpeg",

                        data=open("../data/two_person.jpg", "rb").read(),

                    )

                ),

            ],

        )

    ],

    config=types.GenerateContentConfig(

        response_modalities=["TEXT", "IMAGE"]  # 텍스트와 이미지 모두 응답

    ),

)

  

# 응답 처리

for part in response.candidates[0].content.parts:

    if part.text is not None:

        print("AI의 설명:")

        print(part.text)

    elif part.inline_data is not None:

        print("생성된 이미지:")

        generated_image = Image.open(BytesIO(part.inline_data.data))

        generated_image.save("../data/two_person_result.jpg")

        generated_image.show()  # 이미지 표시
```


---

### 코드 분석

**1. 라이브러리 import**


```python
from google import genai
from google.genai import types
from PIL import Image
from io import BytesIO
```

- `genai`, `types`: Google Generative AI API를 사용하기 위한 핵심 라이브러리입니다.
    
- `PIL.Image`: 이미지를 열고, 표시하고, 저장하는 데 사용되는 파이썬 이미지 라이브러리입니다.
    
- `io.BytesIO`: 메모리에 있는 이미지 바이너리 데이터를 다루기 위한 모듈입니다.
    

**2. 클라이언트 초기화 및 텍스트 프롬프트 정의**


```python
client = genai.Client()

text_prompt = "이미지의 두 사람이 서있는 곳을 해변 배경으로 변경하고, 하늘에 아름다운 노을을 그려주세요"
```

- `client = genai.Client()`: Google AI 서비스에 연결하기 위한 클라이언트 객체를 생성합니다.
    
- `text_prompt`: 모델에 전달할 지시사항입니다. "**two_person.jpg**" 이미지의 배경을 **해변**으로 바꾸고, 하늘에 **노을**을 추가해 달라고 요청하고 있습니다.
    

**3. 이미지 생성 API 호출**


```python
response = client.models.generate_content(
    model="gemini-2.0-flash-preview-image-generation",
    contents=[
        types.Content(
            role="user",
            parts=[
                types.Part(text=text_prompt),
                types.Part(
                    inline_data=types.Blob(
                        mime_type="image/jpeg",
                        data=open("../data/two_person.jpg", "rb").read(),
                    )
                ),
            ],
        )
    ],
    config=types.GenerateContentConfig(
        response_modalities=["TEXT", "IMAGE"]
    ),
)
```

이 부분이 텍스트 프롬프트와 이미지를 함께 모델에 보내는 핵심 코드입니다.

- `model="gemini-2.0-flash-preview-image-generation"`: 텍스트와 이미지를 모두 입력받아 처리할 수 있는 Gemini 모델을 사용합니다.
    
- `contents=[...]`: 모델에 전달할 콘텐츠를 리스트 형태로 정의합니다.
    
    - `types.Content(role="user", ...)`: 사용자 역할을 하는 콘텐츠 블록을 만듭니다.
        
    - `parts=[...]`: 이 콘텐츠 블록은 텍스트와 이미지를 담는 두 개의 `Part`로 구성됩니다.
        
        - `types.Part(text=text_prompt)`: 이전에 정의한 텍스트 프롬프트를 담습니다.
            
        - `types.Part(inline_data=...)`: `two_person.jpg` 파일을 바이너리 형태로 읽어와 이미지 데이터로 전달합니다. `mime_type`은 `image/jpeg`로 지정됩니다.
            
- `config=types.GenerateContentConfig(response_modalities=["TEXT", "IMAGE"])`: 응답으로 텍스트와 이미지 모두를 받도록 설정합니다.
    

**4. 응답 처리 및 이미지 저장**


```python
for part in response.candidates[0].content.parts:
    if part.text is not None:
        print("AI의 설명:")
        print(part.text)
    elif part.inline_data is not None:
        print("생성된 이미지:")
        generated_image = Image.open(BytesIO(part.inline_data.data))
        generated_image.save("../data/two_person_result.jpg")
        generated_image.show()
```

- `response.candidates[0].content.parts`: 모델이 생성한 응답의 첫 번째 후보에 있는 각 부분을 순회합니다.
    
- `if part.text is not None`: 응답이 텍스트일 경우, 해당 내용을 출력합니다.
    
- `elif part.inline_data is not None`: 응답이 이미지 데이터일 경우, `BytesIO`를 사용하여 데이터를 이미지 객체로 변환합니다.
    
    - `generated_image.save(...)`: 변환된 이미지를 `two_person_result.jpg` 파일로 저장합니다.
        
    - `generated_image.show()`: 생성된 이미지를 화면에 표시합니다.







# 텍스트 + 이미지 → 이미지 생성 (다양한 예제)

```python
# 예제 1: 이미지 스타일 변경

from google import genai

from google.genai import types

from PIL import Image

from io import BytesIO

  

client = genai.Client()

  

# 원본 이미지

original_image = Image.open("../data/mark.jpg")

  

# 스타일 변경 프롬프트

style_prompt = "이 이미지를 만화 스타일로 변경해주세요. 밝고 화려한 색상을 사용해주세요."

  

response = client.models.generate_content(

    model="gemini-2.0-flash-preview-image-generation",

    contents=[

        types.Content(

            role="user",

            parts=[

                types.Part(text=style_prompt),

                types.Part(

                    inline_data=types.Blob(

                        mime_type="image/jpeg",

                        data=open("../data/mark.jpg", "rb").read(),

                    )

                ),

            ],

        )

    ],

    config=types.GenerateContentConfig(

        response_modalities=["TEXT", "IMAGE"]  # 텍스트와 이미지 모두 응답 (필수)

    ),

)

  

# 생성된 이미지와 설명 표시

for part in response.candidates[0].content.parts:

    if part.text is not None:

        print("AI의 설명:", part.text)

    elif part.inline_data is not None:

        styled_image = Image.open(BytesIO(part.inline_data.data))

        styled_image.show()
```


---

### 코드 분석

#### 1. 라이브러리 및 클라이언트 초기화


```python
from google import genai
from google.genai import types
from PIL import Image
from io import BytesIO

client = genai.Client()
```

- `genai`, `types`, `PIL.Image`, `io.BytesIO`: 이 부분은 Google GenAI API를 사용하고 이미지 파일을 처리하기 위한 표준 라이브러리를 가져옵니다.
    
- `client = genai.Client()`: API 호출을 위한 클라이언트 객체를 생성합니다.
    

#### 2. 원본 이미지 로드 및 프롬프트 정의


```python
original_image = Image.open("../data/mark.jpg")

style_prompt = "이 이미지를 만화 스타일로 변경해주세요. 밝고 화려한 색상을 사용해주세요."
```

- `original_image = Image.open(...)`: `../data/mark.jpg` 경로에 있는 원본 이미지를 불러와 `original_image` 변수에 저장합니다.
    
- `style_prompt`: 모델에게 전달할 지시사항을 텍스트로 정의합니다. "**만화 스타일**"로 변경하고, "**밝고 화려한 색상**"을 사용해달라고 요청하고 있습니다.
    

#### 3. Gemini 모델 호출


```python
response = client.models.generate_content(
    model="gemini-2.0-flash-preview-image-generation",
    contents=[
        types.Content(
            role="user",
            parts=[
                types.Part(text=style_prompt),
                types.Part(
                    inline_data=types.Blob(
                        mime_type="image/jpeg",
                        data=open("../data/mark.jpg", "rb").read(),
                    )
                ),
            ],
        )
    ],
    config=types.GenerateContentConfig(
        response_modalities=["TEXT", "IMAGE"]
    ),
)
```

- `client.models.generate_content()`: 텍스트와 이미지를 모두 입력받는 Gemini 모델을 호출합니다.
    
- `model="gemini-2.0-flash-preview-image-generation"`: 텍스트-이미지 멀티모달 기능을 가진 Gemini 모델을 사용합니다.
    
- `contents=[...]`: 텍스트와 이미지 데이터를 함께 전달하기 위한 구조입니다.
    
    - `types.Part(text=style_prompt)`: 스타일 변경을 요청하는 텍스트 프롬프트입니다.
        
    - `types.Part(inline_data=...)`: `../data/mark.jpg` 파일의 바이너리 데이터를 포함합니다.
        
- `config=types.GenerateContentConfig(...)`: 응답으로 텍스트와 이미지를 모두 받도록 설정합니다.
    

#### 4. 응답 처리 및 이미지 표시


```python
for part in response.candidates[0].content.parts:
    if part.text is not None:
        print("AI의 설명:", part.text)
    elif part.inline_data is not None:
        styled_image = Image.open(BytesIO(part.inline_data.data))
        styled_image.show()
```

- `response.candidates[0].content.parts`: 모델의 응답에서 텍스트와 이미지 부분을 하나씩 가져옵니다.
    
- `if part.text is not None`: 응답에 텍스트가 포함되어 있다면, AI가 생성한 설명을 출력합니다.
    
- `elif part.inline_data is not None`: 응답에 이미지 데이터가 포함되어 있다면, 해당 데이터를 PIL Image 객체로 변환하고 `show()` 함수를 사용해 화면에 표시합니다.






```python
# 예제 2: 이미지에 객체 추가/제거

from google import genai

from google.genai import types

from PIL import Image

from io import BytesIO

  

client = genai.Client()

  

base_image = Image.open("../data/mark.jpg")

  

# 객체 추가 프롬프트

addition_prompt = """

이 이미지에 다음을 추가해주세요:

1. 배경에 아름다운 산과 나무들

2. 하늘에 흰 구름들

3. 인물 옆에 귀여운 강아지 한 마리

자연스럽게 합성해주세요.

"""

  

response = client.models.generate_content(

    model="gemini-2.0-flash-preview-image-generation",

    contents=[

        types.Content(

            role="user",

            parts=[

                types.Part(text=addition_prompt),

                types.Part(

                    inline_data=types.Blob(

                        mime_type="image/jpeg",

                        data=open("../data/mark.jpg", "rb").read(),

                    )

                ),

            ],

        )

    ],

    config=types.GenerateContentConfig(response_modalities=["TEXT", "IMAGE"]),

)

  

# 결과 출력

for part in response.candidates[0].content.parts:

    if part.text is not None:

        print("편집 설명:", part.text)

    elif part.inline_data is not None:

        edited_image = Image.open(BytesIO(part.inline_data.data))

        edited_image.show()
```


---

### 코드 분석

#### 1. 라이브러리 및 클라이언트 초기화


```python
from google import genai
from google.genai import types
from PIL import Image
from io import BytesIO

client = genai.Client()
```

- `genai`, `types`, `PIL.Image`, `io.BytesIO`: 이 코드 역시 Google GenAI API와 이미지 처리를 위한 필수 라이브러리를 가져옵니다.
    
- `client = genai.Client()`: API와 통신하기 위한 클라이언트 객체를 생성합니다.
    

#### 2. 원본 이미지 로드 및 프롬프트 정의


```python
base_image = Image.open("../data/mark.jpg")

addition_prompt = """
이 이미지에 다음을 추가해주세요:
1. 배경에 아름다운 산과 나무들
2. 하늘에 흰 구름들
3. 인물 옆에 귀여운 강아지 한 마리
자연스럽게 합성해주세요.
"""
```

- `base_image = Image.open(...)`: `../data/mark.jpg` 경로에 있는 원본 이미지를 불러와 `base_image` 변수에 저장합니다.
    
- `addition_prompt`: 모델에 전달할 지시사항을 정의합니다. **배경에 산과 나무, 하늘에 구름, 인물 옆에 강아지**를 추가해달라는 구체적인 요청이 담겨 있습니다. 이처럼 여러 지시를 목록 형태로 제공하여 모델이 복합적인 작업을 수행하도록 유도할 수 있습니다.
    

#### 3. Gemini 모델 호출


```python
response = client.models.generate_content(
    model="gemini-2.0-flash-preview-image-generation",
    contents=[
        types.Content(
            role="user",
            parts=[
                types.Part(text=addition_prompt),
                types.Part(
                    inline_data=types.Blob(
                        mime_type="image/jpeg",
                        data=open("../data/mark.jpg", "rb").read(),
                    )
                ),
            ],
        )
    ],
    config=types.GenerateContentConfig(response_modalities=["TEXT", "IMAGE"]),
)
```

- `client.models.generate_content()`: 텍스트와 이미지를 함께 입력받아 새로운 콘텐츠를 생성하는 Gemini 모델을 호출합니다.
    
- `model="gemini-2.0-flash-preview-image-generation"`: 텍스트-이미지 멀티모달 모델을 사용합니다.
    
- `contents=[...]`: `addition_prompt`에 정의된 텍스트와 `../data/mark.jpg` 이미지 파일을 바이너리 형태로 함께 전달합니다.
    
- `config=types.GenerateContentConfig(...)`: 응답으로 **텍스트와 이미지 모두**를 받도록 설정합니다.
    

#### 4. 응답 처리 및 이미지 표시


```python
for part in response.candidates[0].content.parts:
    if part.text is not None:
        print("편집 설명:", part.text)
    elif part.inline_data is not None:
        edited_image = Image.open(BytesIO(part.inline_data.data))
        edited_image.show()
```

- `response.candidates[0].content.parts`: 모델의 응답에서 텍스트와 이미지 부분을 하나씩 가져옵니다.
    
- `if part.text is not None`: 응답에 텍스트가 있다면, AI가 생성한 편집 설명을 출력합니다.
    
- `elif part.inline_data is not None`: 응답에 이미지 데이터가 있다면, `BytesIO`를 이용해 이미지 객체로 변환하고 `show()` 함수를 사용해 화면에 표시합니다. 이 이미지는 프롬프트에 따라 객체가 추가된 결과물입니다.