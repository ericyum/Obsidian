
# 사전 작업

.env파일을 다음과 같이 작성한다.

```
GOOGLE_API_KEY=(발급 받은 구글 API KEY)

OPENAI_API_KEY=(발급 받은 OpenAI API KEY)
```





# OpenAI QuickStart Example

```python
from openai import OpenAI

  

# Initialize the OpenAI client

# Make sure to set your OpenAI API key in the environment variable OPENAI_API_KEY

client = OpenAI()

  

response = client.chat.completions.create(

    model="gpt-4o-mini",

    messages=[

        {

            "role": "user",

            "content": "유니콘에 대한 한 문장짜리 잠자리 이야기 작성해 주세요.",

        }

    ],

)

  

print(response.choices[0].message.content)
```


---

### 코드 분석

**1. 라이브러리 및 클라이언트 초기화**


```python
from openai import OpenAI

# Initialize the OpenAI client
# Make sure to set your OpenAI API key in the environment variable OPENAI_API_KEY
client = OpenAI()
```

- `from openai import OpenAI`: OpenAI API와 상호작용하기 위한 공식 Python 라이브러리를 가져옵니다.
    
- `client = OpenAI()`: OpenAI 클라이언트 객체를 생성합니다. 이 객체를 통해 API를 호출할 수 있습니다. 주석에 나와 있듯이, API 키는 환경 변수 `OPENAI_API_KEY`에 설정되어 있어야 합니다.
    

**2. 채팅 완료(Chat Completions) 요청**

```python
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {
            "role": "user",
            "content": "유니콘에 대한 한 문장짜리 잠자리 이야기 작성해 주세요.",
        }
    ],
)
```

이 부분이 OpenAI 모델에 요청을 보내는 핵심 코드입니다.

- `client.chat.completions.create()`: 텍스트를 생성하는 Chat Completions API를 호출합니다. 이 API는 대화(채팅) 형식으로 모델과 상호작용할 때 주로 사용됩니다.
    
- `model="gpt-4o-mini"`: 사용할 모델을 지정합니다. 여기서는 `gpt-4o-mini`라는 모델을 사용하고 있습니다. 이 모델은 GPT-4o 모델의 더 작고 빠른 버전으로, 비용 효율성이 높습니다.
    
- `messages=[...]`: 모델에게 전달할 대화 내용을 리스트 형태로 정의합니다.
    
    - `{"role": "user", "content": "..."}`: 사용자의 발언을 나타냅니다. `role`은 `user`(사용자), `system`(시스템), `assistant`(AI) 중 하나를 사용하며, `content`에는 실제 텍스트 내용이 들어갑니다. 여기서는 "유니콘에 대한 한 문장짜리 잠자리 이야기 작성해 주세요."라는 요청을 전달하고 있습니다.
        

**3. 응답 출력**


```python
print(response.choices[0].message.content)
```

- `response.choices[0]`: OpenAI API의 응답은 여러 개의 후보(`choices`)를 포함할 수 있습니다. 이 코드는 그중 첫 번째 후보를 선택합니다.
    
- `.message.content`: 선택된 후보의 메시지 객체에서 실제 텍스트 내용을 추출합니다.
    
- `print(...)`: 추출된 텍스트, 즉 AI가 생성한 잠자리 이야기를 콘솔에 출력합니다.



# OpenAI 호환성

```python
import os

api_key = os.getenv("GOOGLE_API_KEY")

from openai import OpenAI

  

client = OpenAI(

    api_key=api_key, base_url="https://generativelanguage.googleapis.com/v1beta/openai/"

)

  

response = client.chat.completions.create(

    model="gemini-2.5-flash",

    messages=[

        {"role": "system", "content": "You are a helpful assistant."},

        {"role": "user", "content": "Explain to me how AI works"},

    ],

)

  

print(response.choices[0].message)
```


---

### 코드 분석

#### 1. 라이브러리 및 API 키 설정


```python
import os

api_key = os.getenv("GOOGLE_API_KEY")

from openai import OpenAI
```

- `import os`: 운영체제 관련 기능을 제공하는 `os` 모듈을 가져옵니다. 환경 변수를 읽을 때 사용됩니다.
    
- `api_key = os.getenv("GOOGLE_API_KEY")`: 환경 변수 `GOOGLE_API_KEY`에 저장된 값을 가져와 `api_key` 변수에 할당합니다. 이 코드는 **OpenAI API 키가 아닌 Google API 키**를 사용하도록 설정하고 있습니다.
    
- `from openai import OpenAI`: OpenAI API와 통신하기 위한 라이브러리를 가져옵니다.
    

#### 2. 클라이언트 초기화


```python
client = OpenAI(
    api_key=api_key, base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)
```

이 부분이 이 코드의 핵심입니다.

- `OpenAI(...)`: OpenAI 클라이언트 객체를 생성합니다.
    
- `api_key=api_key`: 위에서 환경 변수로 가져온 **Google API 키**를 `api_key` 매개변수에 전달합니다.
    
- `base_url="https://generativelanguage.googleapis.com/v1beta/openai/"`: OpenAI 라이브러리가 기본적으로 사용하는 OpenAI API 엔드포인트 대신, **Google의 Generative Language API 엔드포인트**를 사용하도록 재정의합니다. 이 덕분에 OpenAI 라이브러리 문법으로 Google 모델을 호출할 수 있습니다.
    

#### 3. 채팅 완료(Chat Completions) 요청


```python
response = client.chat.completions.create(
    model="gemini-2.5-flash",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Explain to me how AI works"},
    ],
)
```

- `client.chat.completions.create()`: OpenAI 라이브러리의 채팅 완료 함수를 호출합니다.
    
- `model="gemini-2.5-flash"`: 호출할 모델을 지정합니다. 여기서는 **Google의 Gemini 모델** 중 하나인 `gemini-2.5-flash`를 사용하고 있습니다.
    
- `messages=[...]`: 대화 기록을 담고 있습니다.
    
    - `{"role": "system", "content": "..."}`: 모델의 역할을 정의합니다. "당신은 도움이 되는 비서입니다."라는 지시를 주고 있습니다.
        
    - `{"role": "user", "content": "..."}`: 사용자 요청을 담고 있습니다. "AI가 어떻게 작동하는지 설명해 주세요"라고 묻고 있습니다.
        

#### 4. 응답 출력


```python
print(response.choices[0].message)
```

- `response.choices[0].message`: API 응답에서 첫 번째 후보의 메시지 객체를 가져옵니다. 이전 예제와 달리 `.content`를 바로 출력하지 않고 메시지 객체 자체를 출력하고 있습니다. 이 경우, 메시지 객체에 포함된 `role`과 `content`가 모두 출력됩니다.



# 활용

```python
import os

  

VERTEXAI = True

  

if VERTEXAI:

    model_name = "gemini-2.5-flash"

    project_id = os.getenv("GOOGLE_CLOUD_PROJECT_ID")

    location = "us-central1"  # or your preferred location

else:

    model_name = "models/gemini-2.5-flash"

    api_key = os.getenv("GOOGLE_API_KEY")
```





```python
from google import genai

  

# import google.generativeai as genai

  

# 클라이언트 인스턴스 생성

if VERTEXAI:

    client = genai.Client(vertexai=True, project=project_id, location=location)

else:

    client = genai.Client(api_key=api_key)

  

# 모델을 지정하고 컨텐츠의 답변을 요청

response = client.models.generate_content(

    model=model_name,

    contents="대한민국의 수도는 어디인가요?",

)

print(response.text)
```


---

### 코드 분석

#### 1. 환경 변수 및 설정


```python
import os

VERTEXAI = True

if VERTEXAI:
    model_name = "gemini-2.5-flash"
    project_id = os.getenv("GOOGLE_CLOUD_PROJECT_ID")
    location = "us-central1"
else:
    model_name = "models/gemini-2.5-flash"
    api_key = os.getenv("GOOGLE_API_KEY")
```

- `VERTEXAI = True`: 이 변수는 코드가 Vertex AI를 사용할지(True), 아니면 일반적인 Generative AI API를 사용할지(False) 결정합니다. 현재 설정은 **Vertex AI**를 사용하도록 되어 있습니다.
    
- `if VERTEXAI`: `VERTEXAI`가 `True`일 경우 실행되는 블록입니다.
    
    - `model_name = "gemini-2.5-flash"`: Vertex AI에서 사용하는 모델 이름은 앞에 `models/`가 붙지 않습니다.
        
    - `project_id = os.getenv("GOOGLE_CLOUD_PROJECT_ID")`: Google Cloud 프로젝트 ID를 환경 변수에서 가져옵니다. Vertex AI를 사용하려면 이 정보가 필요합니다.
        
    - `location = "us-central1"`: 모델이 배포된 리전을 지정합니다.
        
- `else`: `VERTEXAI`가 `False`일 경우 실행되는 블록입니다.
    
    - `model_name = "models/gemini-2.5-flash"`: Generative AI API를 사용할 때는 모델 이름 앞에 `models/`를 붙여야 합니다.
        
    - `api_key = os.getenv("GOOGLE_API_KEY")`: Generative AI API를 사용하려면 API 키가 필요하며, 이를 환경 변수에서 가져옵니다.
        

#### 2. 클라이언트 인스턴스 생성


```python
from google import genai

if VERTEXAI:
    client = genai.Client(vertexai=True, project=project_id, location=location)
else:
    client = genai.Client(api_key=api_key)
```

- `from google import genai`: Google Generative AI 라이브러리를 가져옵니다.
    
- `if VERTEXAI`: `genai.Client()` 객체를 생성할 때 `vertexai=True`, `project`, `location` 매개변수를 전달합니다. 이 설정은 Vertex AI 환경에서 모델을 사용하겠다는 의미입니다.
    
- `else`: `api_key` 매개변수만 사용하여 일반적인 Generative AI API 클라이언트를 생성합니다.
    

#### 3. 모델 호출 및 응답 출력


```python
response = client.models.generate_content(
    model=model_name,
    contents="대한민국의 수도는 어디인가요?",
)
print(response.text)
```

- `client.models.generate_content()`: 클라이언트 객체를 통해 콘텐츠 생성 함수를 호출합니다.
    
- `model=model_name`: 위에서 정의한 `model_name` 변수를 사용하여 모델을 지정합니다.
    
- `contents="대한민국의 수도는 어디인가요?"`: 모델에 전달할 텍스트 프롬프트입니다.
    
- `print(response.text)`: API 응답 객체에서 생성된 텍스트(`response.text`)를 추출하여 콘솔에 출력합니다.