
# 사전 작업

.env파일을 다음과 같이 작성한다.

```
GOOGLE_API_KEY=(발급 받은 구글 API KEY)

OPENAI_API_KEY=(발급 받은 OpenAI API KEY)

GOOGLE_CLOUD_PROJECT_ID=(내가 만든 GCP 프로젝트의 ID)
```





# Google AI Studio 동영상 이해(요약)

```python
import os

from dotenv import load_dotenv

from google import genai

  

# .env 파일에서 환경변수 로드

load_dotenv()
```



```python
# Google AI API 키 설정

api_key = os.getenv("GOOGLE_API_KEY")

  

# Only for videos of size <20Mb

video_file_name = "../data/sand-dam.mp4"

model_name = "models/gemini-2.5-flash"

prompt = "이 비디오의 내용을 3개 문장으로 요약해 주세요."

mime_type = "video/mp4"
```



```python
from google.genai import types

  

video_bytes = open(video_file_name, "rb").read()

  

# 클라이언트 초기화

client = genai.Client(api_key=api_key)

response = client.models.generate_content(

    model=model_name,

    contents=types.Content(

        parts=[

            types.Part(inline_data=types.Blob(data=video_bytes, mime_type=mime_type)),

            types.Part(text=prompt),

        ]

    ),

)

  

print(response.text)
```


---

### 코드 분석

#### 1. 환경 변수 및 라이브러리 설정


```python
import os
from dotenv import load_dotenv
from google import genai

load_dotenv()
```

- `import os`: 운영체제 기능을 사용해 환경 변수에 접근합니다.
    
- `from dotenv import load_dotenv`: `.env` 파일에 저장된 환경 변수들을 로드하는 데 사용되는 라이브러리입니다. 보안상 중요한 API 키 등을 코드에 직접 노출하지 않고 관리할 수 있게 해줍니다.
    
- `from google import genai`: Google Generative AI API를 사용하기 위한 라이브러리입니다.
    
- `load_dotenv()`: 현재 디렉터리나 상위 디렉터리의 `.env` 파일을 찾아 환경 변수를 로드합니다.
    

#### 2. 변수 정의 및 파일 설정


```python
api_key = os.getenv("GOOGLE_API_KEY")
video_file_name = "../data/sand-dam.mp4"
model_name = "models/gemini-2.5-flash"
prompt = "이 비디오의 내용을 3개 문장으로 요약해 주세요."
mime_type = "video/mp4"
```

- `api_key = os.getenv("GOOGLE_API_KEY")`: `.env` 파일에서 "GOOGLE_API_KEY" 환경 변수 값을 가져와 API 키로 설정합니다.
    
- `video_file_name = "../data/sand-dam.mp4"`: 분석할 동영상 파일의 경로를 지정합니다. 주석에 따르면 20MB 미만의 작은 동영상 파일에만 적용됩니다.
    
- `model_name = "models/gemini-2.5-flash"`: 동영상 분석 기능을 지원하는 Google의 **`gemini-2.5-flash`** 모델을 사용합니다.
    
- `prompt`: 모델에게 동영상의 내용을 **세 문장으로 요약**해 달라는 지시를 내립니다.
    
- `mime_type = "video/mp4"`: 동영상 파일의 MIME 타입이 `video/mp4`임을 명시합니다.
    

#### 3. 동영상 데이터 로드 및 API 호출


```python
from google.genai import types

video_bytes = open(video_file_name, "rb").read()

client = genai.Client(api_key=api_key)
response = client.models.generate_content(
    model=model_name,
    contents=types.Content(
        parts=[
            types.Part(inline_data=types.Blob(data=video_bytes, mime_type=mime_type)),
            types.Part(text=prompt),
        ]
    ),
)
```

- `video_bytes = open(video_file_name, "rb").read()`: `sand-dam.mp4` 파일을 바이너리 읽기 모드(`"rb"`)로 열어 파일 전체를 읽고 `video_bytes`에 저장합니다.
    
- `client = genai.Client(api_key=api_key)`: API 키를 사용하여 `genai` 클라이언트 객체를 생성합니다.
    
- `client.models.generate_content(...)`: `generate_content` 함수를 사용하여 모델에 요청을 보냅니다.
    
    - `contents=types.Content(...)`: 모델에 전달할 콘텐츠를 정의합니다.
        
    - `parts=[...]`: 이 콘텐츠는 동영상 데이터와 텍스트 프롬프트 두 부분으로 구성됩니다.
        
        - `types.Part(inline_data=...)`: 동영상 파일의 바이너리 데이터(`video_bytes`)와 MIME 타입 정보를 담아 전달합니다.
            
        - `types.Part(text=prompt)`: 이전에 정의한 요약 요청 프롬프트를 전달합니다.
            

#### 4. 응답 출력


```python
print(response.text)
```

- `response.text`: API 응답 객체에서 모델이 생성한 텍스트, 즉 동영상 요약 내용을 추출합니다.
    
- `print(...)`: 추출된 텍스트를 콘솔에 출력합니다.


# 주의!

실행하기 전에 GCP 인증 절차를 해야 정상적으로 실행이 됩니다.



# Vertex AI Studio 동영상 이해(요약)

```python
# Vertex AI 클라이언트 초기화 (프로젝트 ID와 위치 설정)

project_id = os.getenv("GOOGLE_CLOUD_PROJECT_ID")  # .env 파일에 추가 필요

location = "us-central1"  # 또는 원하는 리전

model_name = "gemini-2.5-flash"  # Vertex AI 모델명 (models/ 접두사 제거)

  

# 아래 내용은 동일

# video_file_name = "sand-dam.mp4"

# prompt = "이 비디오의 내용을 3개 문장으로 요약해 주세요."

# mime_type = "video/mp4"
```



```python
# 통합된 google.genai를 사용한 Vertex AI 비디오 분석

from google import genai

from google.genai import types

  

# Vertex AI 클라이언트 생성

vertex_client = genai.Client(vertexai=True, project=project_id, location=location)

  

video_bytes = open(video_file_name, "rb").read()

  

# Vertex AI를 통한 컨텐츠 생성 (올바른 메시지 형식 사용)

response = vertex_client.models.generate_content(

    model=model_name,  # Vertex AI는 models/ 접두사 없음

    contents=[

        types.Content(

            role="user",

            parts=[

                types.Part(

                    inline_data=types.Blob(data=video_bytes, mime_type=mime_type)

                ),

                types.Part(text=prompt),

            ],

        )

    ],

)

  

print("=== Vertex AI 결과 (통합된 genai 라이브러리 사용) ===")

print(response.text)
```


---

### 코드 분석

#### 1. 환경 설정 및 변수 정의


```python
import os

project_id = os.getenv("GOOGLE_CLOUD_PROJECT_ID")
location = "us-central1"
model_name = "gemini-2.5-flash"
# video_file_name = "sand-dam.mp4"
# prompt = "이 비디오의 내용을 3개 문장으로 요약해 주세요."
# mime_type = "video/mp4"
```

- `project_id = os.getenv(...)`: **Google Cloud 프로젝트 ID**를 환경 변수에서 가져옵니다. Vertex AI를 사용하려면 이 정보가 반드시 필요합니다.
    
- `location = "us-central1"`: Vertex AI 모델이 호스팅된 **리전(region)**을 설정합니다.
    
- `model_name = "gemini-2.5-flash"`: 사용할 모델 이름을 정의합니다. 일반 Generative AI API와 달리, Vertex AI에서는 모델 이름 앞에 `models/` 접두사가 필요 없습니다.
    
- 주석 처리된 부분은 이전 코드에서 정의된 변수들이며, 이 예제에서는 동일한 값들을 사용한다는 것을 가정하고 있습니다.
    

#### 2. 클라이언트 초기화


```python
from google import genai
from google.genai import types

vertex_client = genai.Client(vertexai=True, project=project_id, location=location)
```

- `from google import genai`, `from google.genai import types`: Google Generative AI 라이브러리를 가져옵니다.
    
- `vertex_client = genai.Client(...)`: **`genai.Client`** 객체를 생성합니다. 이 코드의 가장 중요한 부분입니다.
    
    - `vertexai=True`: 이 매개변수는 클라이언트가 일반 API 대신 **Vertex AI 환경**에 연결해야 함을 명시합니다.
        
    - `project=project_id`, `location=location`: Vertex AI에 접속하기 위한 필수 정보인 **프로젝트 ID**와 **리전**을 전달합니다.
        

#### 3. 동영상 데이터 로드 및 API 호출


```python
video_bytes = open(video_file_name, "rb").read()

response = vertex_client.models.generate_content(
    model=model_name,
    contents=[
        types.Content(
            role="user",
            parts=[
                types.Part(inline_data=types.Blob(data=video_bytes, mime_type=mime_type)),
                types.Part(text=prompt),
            ],
        )
    ],
)
```

- `video_bytes = open(...)`: 동영상 파일(`sand-dam.mp4`)을 바이너리 형태로 읽어와 변수에 저장합니다.
    
- `vertex_client.models.generate_content(...)`: 생성한 `vertex_client`를 사용하여 `gemini-2.5-flash` 모델에 요청을 보냅니다.
    
    - `model=model_name`: Vertex AI용으로 설정된 모델 이름을 사용합니다.
        
    - `contents=[...]`: 이전 예제와 동일하게, `inline_data`에 **동영상 데이터**를, `text`에 **요약 요청 프롬프트**를 담아 전달합니다. 이 구조는 멀티모달 콘텐츠를 모델에 전달하는 표준 방식입니다.
        

#### 4. 응답 출력


```python
print("=== Vertex AI 결과 (통합된 genai 라이브러리 사용) ===")
print(response.text)
```

- `response.text`: 모델의 응답 객체에서 텍스트 부분만 추출하여 출력합니다. 이 텍스트는 동영상의 요약 내용이 될 것입니다.