#### 1. 모델 관리 기능 요약

- **Chat-Models**:
    
    - **개념**: 대화형 모델(챗 모델)을 추상화한 클래스입니다. LLM과는 달리 입력과 출력이 메시지(메시지 리스트) 형태로 구성됩니다.
        
    - **역할**: OpenAI의 `gpt-3.5-turbo`, Google의 `Gemini`, Anthropic의 `Claude` 등 다양한 챗 모델 API를 통일된 인터페이스로 호출할 수 있게 해줍니다. 시스템 메시지, 사용자 메시지, AI 메시지 등 각 메시지의 역할을 명확히 구분하여 모델에 전달합니다.
        
- **Cache (캐시)**:
    
    - **개념**: LLM 호출 결과를 저장하여 동일한 요청에 대한 재호출을 방지하는 기능입니다.
        
    - **역할**: LLM API 호출은 비용과 시간이 소요되므로, 동일한 프롬프트에 대한 응답을 메모리, 파일, 데이터베이스 등에 캐시하여 중복 호출을 막고 성능을 개선하며 비용을 절감합니다.
        
- **Model Serialization (모델 직렬화)**:
    
    - **개념**: LangChain 체인, 에이전트, 프롬프트, 모델 등을 파일로 저장하고 다시 불러오는 기능입니다.
        
    - **역할**: 작업 환경을 재구축하거나, 훈련된 모델 및 체인 구성을 공유하고 싶을 때 유용합니다. 복잡한 체인 구성을 `.json` 또는 `.yaml` 파일로 저장하여, 코드를 다시 작성할 필요 없이 쉽게 로드하여 사용할 수 있습니다.