# LlamaParser

LlamaParse는 LlamaIndex에서 개발한 문서 파싱 서비스로, 대규모 언어 모델(LLM)을 위해 특별히 설계되었습니다.

주요 특징은 다음과 같습니다:

- PDF, Word, PowerPoint, Excel 등 다양한 문서 형식 지원
    
- 자연어 지시를 통한 맞춤형 출력 형식 제공
    
- 복잡한 표와 이미지 추출 기능
    
- JSON 모드 지원
    
- 외국어 지원
    

LlamaParse는 독립형 API로 제공되며, LlamaCloud 플랫폼의 일부로도 사용 가능합니다. 이 서비스는 문서를 파싱하고 정제하여 검색 증강 생성(RAG) 등 LLM 기반 애플리케이션의 성능을 향상시키는 것을 목표로 합니다.

사용자는 무료로 하루 1,000페이지를 처리할 수 있으며, 유료 플랜을 통해 추가 용량을 확보할 수 있습니다. LlamaParse는 현재 공개 베타 버전으로 제공되고 있으며, 지속적으로 기능이 확장되고 있습니다.

- 링크: [https://cloud.llamaindex.ai](https://cloud.llamaindex.ai)
    

**API 키 설정**

- API 키를 발급 후 `.env` 파일에 `LLAMA_CLOUD_API_KEY` 에 설정합니다.
    

Python

```
# 설치
# !pip install llama-index-core llama-parse llama-index-readers-file python-dotenv
```

Python

```
import os
import nest_asyncio
from dotenv import load_dotenv

load_dotenv()
nest_asyncio.apply()
```

Python

```
# import os
# os.getenv("LLAMA_CLOUD_API_KEY")
```

기본 파서 적용

1. result_type
    
    - 파싱된 결과의 출력 형식을 지정합니다.
        
2. num_workers
    
    - 병렬 파싱을 수행할 때 사용할 워커(worker) 수를 지정합니다.
        
3. verbose
    
    - 파싱 과정의 상세 로그를 출력할지 여부.
        
4. language
    
    - 문서의 주요 언어를 지정.
        

Python

```
from llama_parse import LlamaParse
from llama_index.core import SimpleDirectoryReader

# 파서 설정
parser = LlamaParse(
    result_type="markdown",  # "markdown"과 "text" 사용 가능
    num_workers=8,  # worker 수 (기본값: 4) # 병렬 파싱을 수행할 때 사용할 워커(worker) 수를 지정
    verbose=True, # 파싱 과정의 상세 로그를 출력할지 여부. True일 경우에는 진행 상황(몇 페이지 처리 중인지, 에러 여부 등)을 콘솔에 출력.
    language="ko", # 문서의 주요 언어를 지정. 대부분의 언어가 한국어일 경우에는 'ko'라고 하면 한국어에 대한 맞춤형 토크나이징, 분석이 적용된다.
)

# SimpleDirectoryReader를 사용하여 파일 파싱
file_extractor = {".pdf": parser}

# LlamaParse로 파일 파싱
documents = SimpleDirectoryReader(
    input_files=["data/SPRI_AI_Brief_2023년12월호_F.pdf"],
    file_extractor=file_extractor,
).load_data()
```

**실행 결과:**

```
Started parsing the file under job_id 744cab61-2200-4edf-8d17-2be7ff88827b
```

Python

```
# 페이지 수 확인
len(documents)
```

**실행 결과:**

```
23
```

Python

```
documents[0]
```

**실행 결과:**

```
Document(id_='39bb7527-09c3-46f3-b746-9d5b8f72f351', embedding=None, metadata={'file_path': 'data\\\\SPRI_AI_Brief_2023년12월호_F.pdf', 'file_name': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_type': 'application/pdf', 'file_size': 975735, 'creation_date': '2025-08-21', 'last_modified_date': '2025-08-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='# 2023년 12월호\\n\\n# 인공지능 산업의 최신 동향\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')
```

LlamaIndex -> LangChain Document 로 변환

Python

```
# 랭체인 도큐먼트로 변환
docs = [doc.to_langchain_format() for doc in documents]
```

Python

```
print(docs[5].page_content)
```

**실행 결과:**

```
# 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언

# KEY Contents

- 영국 블레츨리 파크에서 개최된 AI 안전성 정상회의에 참가한 28개국들이 AI 안전 보장을 위한 협력 방안을 담은 블레츨리 선언을 발표
- 첨단 AI를 개발하는 국가와 기업들은 AI 시스템에 대한 안전 테스트 계획에 합의했으며, 영국의 AI 안전 연구소가 전 세계 국가와 협력해 테스트를 주도할 예정

# AI 안전성 정상회의 참가국들, 블레츨리 선언 통해 AI 안전 보장을 위한 협력에 합의

- 2023년 11월 1~2일 영국 블레츨리 파크에서 열린 AI 안전성 정상회의(AI Safety Summit)에 참가한 28개국 대표들이 AI 위험 관리를 위한 ‘블레츨리 선언’을 발표
- 선언은 AI 안전 보장을 위해 국가, 국제기구, 기업, 시민사회, 학계를 포함한 모든 이해관계자의 협력이 중요하다고 강조했으며, 특히 최첨단 AI 시스템 개발 기업은 안전 평가를 비롯한 적절한 조치를 취하여 AI 시스템의 안전을 보장할 책임이 있다고 지적
- 각국은 AI 안전 보장을 위해 첨단 AI 개발기업의 투명성 향상, 적절한 평가지표와 안전 테스트 도구 개발, 공공부문 역량 구축과 과학 연구개발 등의 분야에서 협력하기로 합의

# 영국 총리, 정부 주도의 첨단 AI 시스템 안전 테스트 계획 발표

- 리시 수낙 영국 총리는 AI 안전성 정상회의를 마무리하며 첨단 AI 모델에 대한 안전성 시험 계획 수립과 테스트 수행을 주도할 영국 AI 안전 연구소의 출범을 발표
- 첨단 AI 모델의 안전 테스트는 국가 안보와 안전, 사회적 피해를 포함한 여러 잠재적 유해 기능에 대한 시험을 포함하며, 참석자들은 정부 주도의 외부 안전 테스트에 합의
- 각국 정부는 테스트와 기타 안전 연구를 위한 공공부문 역량에 투자하고, 테스트 결과가 다른 국가와 관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 노력하기로 합의

- 참가국들은 튜링상을 수상한 AI 학자인 요슈아 벤지오 교수가 주도하는 ‘과학의 현황(State of the Science)’ 보고서 작성에도 합의했으며, 보고서를 통해 첨단 AI의 위험과 가능성에 관한 기존 연구를 과학적으로 평가하고 향후 AI 안전 연구를 위한 우선순위를 제시할 계획
- 한국은 영국 정부와 6개월 뒤에 온라인으로 AI 미니 정상회의를 공동 개최하기로 합의했으며, 프랑스 정부와는 1년 후 대면 정상회의를 개최할 예정

☞ 출처: Gov.uk, The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023, 2023.11.01. Gov.uk, World leaders, top AI companies set out plan for safety testing of frontier as first global AI Safety Summit concludes, 2023.11.02.
```

Python

```
# metadata 출력
docs[0].metadata
```

**실행 결과:**

```
{'file_path': 'data\\\\SPRI_AI_Brief_2023년12월호_F.pdf',
 'file_name': 'SPRI_AI_Brief_2023년12월호_F.pdf',
 'file_type': 'application/pdf',
 'file_size': 975735,
 'creation_date': '2025-08-21',
 'last_modified_date': '2025-08-21'}
```

## MultiModal Model 로 파싱

**주요 파라미터**

- `use_vendor_multimodal_model`: 멀티모달 모델 사용 여부를 지정합니다. `True`로 설정하면 외부 벤더의 멀티모달 모델을 사용합니다.
    
- `vendor_multimodal_model_name`: 사용할 멀티모달 모델의 이름을 지정합니다. 여기서는 "openai-gpt4o"를 사용하고 있습니다.
    
- `vendor_multimodal_api_key`: 멀티모달 모델 API 키를 지정합니다. 환경 변수에서 OpenAI API 키를 가져옵니다.
    
- `result_type`: 파싱 결과의 형식을 지정합니다. "markdown"으로 설정되어 있어 결과가 마크다운 형식으로 반환됩니다.
    
- `language`: 파싱할 문서의 언어를 지정합니다. "ko"로 설정되어 한국어로 처리됩니다.
    
- `skip_diagonal_text`: 대각선 텍스트를 건너뛸지 여부를 결정합니다.
    
- `page_separator`: 페이지 구분자를 지정할 수 있습니다.
    

Python

```
documents = LlamaParse(
    use_vendor_multimodal_model=True,
    vendor_multimodal_model_name="openai-gpt4o",
    vendor_multimodal_api_key=os.environ["OPENAI_API_KEY"],
    result_type="markdown",
    language="ko",
    # skip_diagonal_text=True,
    # page_separator="\n=================\n"
)
```

Python

```
# parsing 된 결과
parsed_docs = documents.load_data(file_path="data/SPRI_AI_Brief_2023년12월호_F.pdf")
```

**실행 결과:**

```
Started parsing the file under job_id 550cc932-2554-497f-9339-8f6917ca21ae
```

Python

```
# langchain 도큐먼트로 변환
docs = [doc.to_langchain_format() for doc in parsed_docs]
```

Python

```
print(docs[18].page_content)
```

**실행 결과:**

```
16

# 구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표

### KEY Contents

- 구글 딥마인드 연구진이 성능과 범용성, 자율성을 기준으로 범용 AI(AGI)의 수준을 0-5단계까지 총 6단계로 구분한 프레임워크를 공개
- 현재 AGI는 단백질 구조를 예측하는 알파폴드와 같은 특정 용도에서는 5단계 수준을 달성했지만 광범위하게 활용될 수 있는 범용에서는 1단계 수준에 머무러 있음

### 챗GPT와 구글 바드와 같은 AI 챗봇은 범용 AI 1단계 수준

- 구글 딥마인드 연구진은 2023년 11월 4일 범용 AI(Artificial General Intelligence, AGI) 모델을 용도와 성능에 따라 분류하는 프레임워크를 제시한 논문을 발표
- 프레임워크의 목적은 AGI의 성능, 범용성, 자율성 수준을 정의하여 모델 간 비교와 위험 평가, AGI 달성까지의 진행 상황을 측정할 수 있는 공통 기준을 제공하기 위함
- 연구진은 AGI 개념 정리에 필요한 기준을 수립하기 위한 6가지 원칙을 아래와 같이 도출
  - (프레시스가 아닌 기능에 중점) AI가 어떻게 작동하는지보다 무엇을 할 수 있는지가 더 중요.
  - (범용성 성능으로 모든 평가) 진정한 AGI는 인간을 능가하는 폭넓은 범용성과 기술의 결합을 모두 요구.
  - (인지와 메타인지 작업에 중점) 물리적 작업의 수행 능력은 AGI의 필수 전제조건이 아니며, 인지 작업과 메타인지 작업(예: 새로운 작업의 학습 능력, 인간에게 도움을 요청할 시점을 아는 능력)이 핵심.
  - (실제 구현보다 잠재력에 집중) 통제된 상황에서 발생하는 성능에 따라 AGI를 규정하고 테스트를 진행.
  - (생태학적 타당도를 갖춘 메타마크 사용) AGI에 대한 벤치마크는 사람들이 경제적·사회적 또는 예측적으로 가치 있게 여기는 실질적인 작업을 대상으로 성능 평가 필요.
  - (중증이 아닌 AGI를 향한 경로에 중점) 단계별 접근방식을 통해 AGI의 발전 상태를 점진적으로 측정.

- 연구진은 상기 원칙에 따라 AI를 성능에 따라 0-5단계로 광범위한 목적에 활용될 수 있는 범용 AI 및 특정 과업에 활용되는 특수 AI로 분류했으며, 특수 AI에서는 5단계까지 달성되었으나, 범용 AI는 현재 1단계 수준

### (구글 딥마인드의 범용 AI 분류 프레임워크)

| 성능 | 특수 AI 예시 | 범용 AI 예시 |
| :--- | :--- | :--- |
| 0단계: AI 아님 | 계산기, 스프레드시트, 엑셀 | 아마존 메커니컬 터크 |
| 1단계: 신뢰(속도보다 인간을 믿음) | GOFAI(Good Old Fashioned Artificial Intelligence) | 챗GPT, 바드, 뉴빙 |
| 2단계: 유능(숙련된 인간의 50% 이상) | 애플 스피커에서 시리, 아마존 알렉사, 구글 어시스턴트, IBM 왓슨 | 미달성 |
| 3단계: 전문가(숙련된 인간의 90% 이상) | 딥러닝(알파패고, 생성 이미지(크리에이터)) | 미달성 |
| 4단계: 최적화(숙련된 인간의 99% 이상) | 딥블루, 알파고 | 미달성 |
| 5단계: 초인간(인간을 100% 능가) | 알파폴드, 챗GPT4, 스톡피시 | 미달성 |

출처: Arxiv.org, Levels of AGI: Operationalizing Progress on the Path to AGI, 2023.11.04.
```

아래와 같이 사용자 정의 인스트럭션을 지정하는 것도 가능합니다.

#### Output: mode에 따라서 출력 형식이 지원이 안되는 경우도 있으니 주의할 것!

[https://docs.cloud.llamaindex.ai/llamaparse/presets_and_modes/output_modes](https://docs.cloud.llamaindex.ai/llamaparse/presets_and_modes/output_modes)

Python

```
# parsing instruction 을 지정합니다.
parsing_instruction = (
    "You are parsing a brief of AI Report. Please extract tables in markdown format."
)

# LlamaParse 설정
parser = LlamaParse(
    use_vendor_multimodal_model=True,
    vendor_multimodal_model_name="openai-gpt4o",
    vendor_multimodal_api_key=os.environ["OPENAI_API_KEY"],
    result_type="markdown",
    language="ko",
    parsing_instruction=parsing_instruction,
)

# parsing 된 결과
parsed_docs = parser.load_data(file_path="data/SPRI_AI_Brief_2023년12월호_F.pdf")

# langchain 도큐먼트로 변환
docs = [doc.to_langchain_format() for doc in parsed_docs]
```

**실행 결과:**

```
WARNING: parsing_instruction is deprecated. Use system_prompt, system_prompt_append or user_prompt instead.
Started parsing the file under job_id 0955f76a-99bb-4123-aa56-e9bc1641d16b
```

Python

```
# markdown 형식으로 추출된 테이블 확인
print(docs[-2].page_content)
```

**실행 결과:**

```
| 행사명 | 행사 주요 개요 | |
| :--- | :--- | :--- |
| CES 2024 | - 미국 소비자기술 협회(CTA)가 주관하는 세계 최대 가전·IT·소비재 전시회로 5G, AR&VR, 디지털헬스, 교통·모빌리티 등 주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시<br>- CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며, 모든 산업을 포함한다는 의미에서 '올 인(All in)'을 주제로 한 이번 전시에는 500곳 이상의 한국기업 참가 예정 | |
| 기간 | 장소 | 홈페이지 |
| 2024.1.9~12 | 미국, 라스베가스 | https://www.ces.tech/ |
| AIMLA 2024 | - 머신러닝 및 응용에 관한 국제 컨퍼런스(AIMLA 2024)는 인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한 지식과 최신 연구 결과 공유<br>- 이론 및 실무 측면에서 인공지능, 기계학습의 주요 분야를 논의하고, 함께, 산업계의 연구자와 실무자들에게 해당 분야의 최첨단 개발 소식 공유 | |
| 기간 | 장소 | 홈페이지 |
| 2024.1.27~28 | 덴마크, 코펜하겐 | https://ccnet2024.org/aimla/index |
| AAAI Conference on Artificial Intelligence | - AI 발전 협회 컨퍼런스(AAAI)는 AI 연구를 촉진하고, AI 분야 연구원, 실무자, 과학자, 학술 및 공학자 간 교류의 기회 제공<br>- 컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사, 워크숍, 튜토리얼, 포스터 세션, 주제 발표, 대회, 전시 프로그램 등 진행 | |
| 기간 | 장소 | 홈페이지 |
| 2024.2.20~27 | 캐나다, 벤쿠버 | https://aaai.org/aaai-conference/ |
```

정리

Python

```
import os

file_path = "data/2103.15348v2.pdf"
parsed_docs = documents.load_data(file_path=file_path)

# langchain 도큐먼트로 변환
docs = [doc.to_langchain_format() for doc in parsed_docs]

# os.path.splitext()를 사용하여 경로와 확장자를 분리하고, 새로운 확장자를 붙입니다.
# file_root는 'data/2103.15348v2'가 됩니다.
file_root, _ = os.path.splitext(file_path)
output_file_path = file_root + ".md"

# 1. 모든 페이지의 page_content를 리스트로 추출합니다.
#    각 페이지 사이를 두 줄 띄어쓰기(\n\n)로 구분하여 가독성을 높입니다.
full_text = "\n\n".join([doc.page_content for doc in docs])

# 2. 추출한 전체 텍스트를 파일에 저장합니다.
#    'w' 모드는 파일을 쓰기 모드로 열며, encoding='utf-8'은 한글 깨짐을 방지합니다.
with open(output_file_path, "w", encoding="utf-8") as f:
    f.write(full_text)

print(f"✅ 파일 저장 완료: {output_file_path}")
```

**실행 결과:**

```
Started parsing the file under job_id d433bb8f-fb05-4260-ae90-4268ee67366c
✅ 파일 저장 완료: data/2103.15348v2.md
```

Python

```
import os
from llama_parse import LlamaParse
from llama_index.core import SimpleDirectoryReader

documents = LlamaParse(result_type="markdown")

def pdf_parser(pdf_file_path: str):
    """
    PDF 파일을 파싱하여 그 내용을 Markdown 파일로 저장합니다.

    Args:
        pdf_file_path (str): 처리할 PDF 파일의 경로.
    """
    print(f"🔄 '{pdf_file_path}' 파일 파싱을 시작합니다...")

    try:
        # parsing instruction 을 지정합니다.
        parsing_instruction = (
            "You are parsing a AI Report. Please extract tables in markdown format."
        )

        # LlamaParse 설정
        parser = LlamaParse(
            use_vendor_multimodal_model=True,
            vendor_multimodal_model_name="openai-gpt4o",
            vendor_multimodal_api_key=os.environ["OPENAI_API_KEY"],
            result_type="markdown",
            parsing_mode="Unstructured",
            language="ko",
            parsing_instruction=parsing_instruction,
        )

        # 1. LlamaParse를 사용하여 PDF 파일을 로드합니다.
        # 'documents' 객체는 이 함수 외부에서 미리 정의되어 있어야 합니다.
        # 아래의 두 방법을 비교 해보자.
        # parsed_docs = parser.load_data(file_path=pdf_file_path) # 멀티 모달, 모델, 파싱 모드 등을 잡다하게 설정한 parser
        parsed_docs = documents.load_data(file_path=pdf_file_path) # 그냥 평범하게 result_type설정만한 parser

        # 2. LangChain 형식의 도큐먼트로 변환합니다.
        docs = [doc.to_langchain_format() for doc in parsed_docs]

        # 3. 저장할 Markdown 파일의 경로를 생성합니다. (확장자 변경)
        file_root, _ = os.path.splitext(pdf_file_path)
        output_file_path = file_root + ".md"

        # 4. 모든 페이지의 내용을 하나의 텍스트로 합칩니다.
        #    페이지 사이는 두 줄로 띄어 가독성을 높입니다.
        full_text = "\n\n".join([doc.page_content for doc in docs])

        # 5. 추출된 전체 텍스트를 .md 파일로 저장합니다.
        with open(output_file_path, "w", encoding="utf-8") as f:
            f.write(full_text)

        print(f"✅ 파일 저장 완료: {output_file_path}")

    except FileNotFoundError:
        print(f"❌ 오류: 파일을 찾을 수 없습니다 - {pdf_file_path}")
    except Exception as e:
        print(f"❌ 오류 발생: {e}")


# --- 함수 사용 예시 ---
# 이 코드를 실행하기 전에 'documents' 파서 객체를 초기화해야 합니다.
# file_to_parse = "data/디지털정부혁신추진계획.pdf"
file_to_parse = "./data/클라우드네이티브1-2.pdf"
pdf_parser(file_to_parse)
```

**실행 결과:**

```
🔄 './data/클라우드네이티브1-2.pdf' 파일 파싱을 시작합니다...
Started parsing the file under job_id 0df9761d-6922-4dad-8da4-5d5e712524c9
✅ 파일 저장 완료: ./data/클라우드네이티브1-2.md
```

1. parser를 잡다하게 설정한 것 보다 그냥 단순하게 마크 다운만 적용한 parser가 오히려 있는 그대로 잘 출력한다.
    
2. 출력 도중 있는 내용이 아닌, 알아서 지어내는 경우가 있으니 주의!
    

[https://docs.cloud.llamaindex.ai/llamaparse/features/supported_document_types](https://docs.cloud.llamaindex.ai/llamaparse/features/supported_document_types)

또한 모든 문서 타입을 다 입력할 수 없고 지원하는 문서 타입들이 따로 한정 되어있으니 주의할 것!

Python

```
import os
import asyncio
from llama_cloud_services import LlamaParse

# --- 1. Llama Cloud API 키 설정 ---
# https://cloud.llamaindex.ai/ 에서 발급받은 API 키를 환경 변수에 설정해야 합니다.
if "LLAMA_CLOUD_API_KEY" not in os.environ:
    # 아래 주석을 해제하고 실제 키를 입력하거나, 시스템 환경 변수를 설정하세요.
    # os.environ["LLAMA_CLOUD_API_KEY"] = "llx-..." 
    print("경고: 'LLAMA_CLOUD_API_KEY' 환경 변수가 설정되지 않았습니다.")

# --- 2. 파싱할 PDF 파일 경로 ---
pdf_file_path = "./data/클라우드네이티브1-3.pdf" # 실제 파일 경로로 수정하세요.

# --- 3. LlamaParse 객체에 고급 옵션 설정 ---
# 요청하신 모든 옵션을 포함하여 파서를 설정합니다.
# result_mode="markdown"이 최종 출력을 마크다운으로 지정하는 핵심 부분입니다.
parser = LlamaParse(
    result_mode="markdown",                # 최종 결과 형식을 마크다운으로 지정
    parse_mode="parse_page_with_agent",    # 에이전트 기반의 페이지별 파싱 모드 사용
    model="openai-gpt-4o-mini",            # 파싱에 사용할 LLM 모델 (gpt-4-1-mini -> gpt-4o-mini로 변경 권장)
    language="ko",
    high_res_ocr=True                      # 고해상도 OCR 활성화 (스캔 문서 처리에 유용)
)

# --- 4. 비동기 함수로 파일 파싱 실행 ---
async def parse_document():
    if "LLAMA_CLOUD_API_KEY" not in os.environ:
        print("API 키가 없어 파싱을 진행할 수 없습니다.")
        return

    print(f"'{pdf_file_path}' 파일 파싱을 시작합니다...")
    try:
        # aload_data 메서드를 사용하여 비동기적으로 파일을 파싱합니다.
        documents = await parser.aload_data(file_path=pdf_file_path)

        # 파싱된 마크다운 결과를 출력합니다.
        if documents:
            print("\n--- 파싱 결과 (마크다운) ---")
            print(documents[0].text)
            print("--------------------------")
        else:
            print("문서에서 내용을 추출하지 못했습니다.")
            
    except Exception as e:
        print(f"오류가 발생했습니다: {e}")

# --- 5. 비동기 함수 실행 ---
if __name__ == "__main__":
    asyncio.run(parse_document())
```

**실행 결과:**

```
'./data/클라우드네이티브1-3.pdf' 파일 파싱을 시작합니다...
Started parsing the file under job_id 6f291fba-754a-4084-8520-21053d4143e3

--- 파싱 결과 (마크다운) ---
 플라우드 네이티브 아키택처의 개요

 단순히 플라우드 환경에서 애플리켜이선올 호스팅하는 것올 넘어서  플라우드의 특성올 최대한 활용하여 애플리키이선올
 설계하고 개발하는 방식울 의미한다. 플라우드 네이티브 아키택처는 이러한 접근 방식울 체계적으로 구현하기 위한 방법론
 과 원직올 제시한다

 플라우드 네이티브   아키택처의 핵심 요소는                    자동화

 로서비스는 애플리켜이선올 독립적으로 배포 가능한 작은 서비스로 나누는 접근 방식으로 각 서비스는 특정 기능울 수행한
 다 이로 인해 개발림은 각 서비스에 대해 독립적으로 개발 테스트 및 배포할 수 있으며 장애 발생 시 전체 시스템에 영향울
 미치지 않도록 할 수 있다

 건테이너 기술은 이러한 마이크로서비스트 배포하고 관리하는 데 중요한 역할울 한다 건테이너는 애플리켜이선과 그 실행
 에 필요한 모든 종속성올 패키장하여 손쉽게 배포할 수 잇도록 해준다: 이논 개발환경과 운영환경 간의 불일치률 줄이고 애

 여 애플리켜이선의 배포와 관리틀 자동화하고 확장성올 용이하게 한다

자동화는 플라우드 네이티브 아키택처의 또 다른 중요한 요소로 배포 테스트 모니터랑 등의 여러 프로세스틀 자동화하여
개발팀의 생산성흘 높인다: 이틀 통해 개발자는 반복적인 작업에 소요되는 시간을 줄이고 더 나아가 학신적인 기능울 개발
하늘 데 집중할 수 있다: 디-디는 이러한 자동화의 대표적인 예로 코드의 변경 사항이 발생활 때마다 자동으로 테스트하고
배포하는 프로세스름 통해 신속하게 기능울 제공활 수 있다:

 플라우드 네이티브 아키택처의 또 다른 장점은 스레일림과 유연성이다: 플라우드 환경은 사용자가 필요에 따라 자원올 동적
으로 조정할 수 있는 유연성올 제공하다: 이논 수요가 급증하는 경우에 즉각적으로 자원올 추가하거나 반대로 수요가 줄어
 드는 경우 자원올 줄일 수 있는 기능을 의미한다. 이러한 스레일림 기능은 플라우드 네이티브 애플리켜이선이 성능올 발휘
 할 수 잇도록 도와준다:

 또한 플라우드 네이티브 아키택처는 장애 복구와 가용성올 높이는 데도 기여하다 마이크로서비스 아키택처는 각 서비스가
 독립적으로 운영되기 때문에 하나의 서비스에 문제가 발생해도 전체 애플리켜이선이 영향울 받지 않도록 설계할 수 있다
 이로 인해 장애 발생 시 빠르게 대처할 수 있는 시스템올 구축할 수 있다: 플라우드 제공업체들은 또한 다양한 장애 복구 및
 백업 슬루선올 제공하여 데이터 손실올 방지하고 운영의 연속성올 보장할 수 있다:

--------------------------
```

위와 같이 high_res_ocr 설정을 통해서 이미지를 보고 글자를 추출해 낼 수 있다. 이때 멀티 모달을 사용하지 않아야 한다. 즉, use_vendor_multimodal_model이 false여야한다는 것이다.