원본파일과 데이터 증식된 파일을 구별  
     
1. 폴더의 파일 목록을 csv로 저장
2. pandas 데이터 프레임에 csv 불러오기  
3. 원본파일과 증식된 파일을 구별하는(pandas 데이터프레임에 컬럼 추가 원본, 복제본 구별하는 컬럼)  
4. 원본 파일이 없는 경우 어떤 파일을 대체제로 사용할지 기준 선정  
5. vertical_flip, salt_and_pepper, translation 순으로 컬럼의 원본을 체크 하는 것으로  
6. 실제 파일을 삭제

# Anaconda Prompt에서 Gemini-CLI 사용하여 폴더의 파일의 종류를 분류

```
(base) C:\Users\SBA>cd github

(base) C:\Users\SBA\github>cd dataset

(base) C:\Users\SBA\github\dataset>gemini
```


1. 각 폴더에는 원본 파일과 증강된 파일 둘이 혼재 되어 있다. 따라서 원본 파일와 증강된 파일들이 어떤 종류가 있고 또 얼마나 각각 있는지를 확인하고 이를 csv파일에 저장한다.
```
C:\Users\SBA\github\dataset\train\freshapples 이 폴더에 Screen으로 시작해서png로 끝나는 파일명 부분을 basename이라고 하고, 파일명에 앞에 붙은 이름을 prefix라고 하면, prefix 문자열의 고유한 값을 추출하는 파이썬 코드를 생성해줘. 
```


```
C:\Users\SBA\github\dataset\train\freshapples 폴더의 파일들을 basename뒤에 prefix문자열이 들어가도록 파일명을 수정해서 C:\Users\SBA\github\dataset\train\freshapples_rec라는 폴더에 파일들을 복사해 줘. prefix를 basename뒤에 붙일때 확장자는 떼서 prefix뒤에 붙게 파일을 생성해 줘.  
```

```
C:\Users\SBA\github\dataset\train\freshapples_re 폴더에서 basename으로된 파일이 없고 prefix파일만 있는 파일 목록을 확인하는 파이썬 파일을 생성해줘
```

```
rotated나 saltandpepper_, translation_, vertical_flip_ 문자열을 포함하는 파일은 데이터 증식된 파일이고, 이 문자열이 없는 파일은 원본파일이야.  
원본파일이 앞에 이름이 동일하고 이러한 문자열을 포함하지 않은 파일이 없는 경우를 찾는 파이썬 코드를 생성해줘.
```

```
C:\Users\SBA\github\dataset\train\freshapples_re 폴더의 파일 목록을 csv파일로 저장해줘
```



2. 그 후 csv파일을 바탕으로 원본 파일을 제외한 증강된 파일들을 삭제한다. 원본 파일이 없고 증강된 파일만 존재하는 경우에는 vertical_flip있는 파일이 1순위 대체파일이고 이 파일도 없으면 salt_and_pepper 문자열이 있는 경우 2순위, translation 문자열이 포함된 순으로 대체제를 선별하고 그 대체제를 제외한 나머지 증강된 파일들을 삭제한다.
```
대상경로 : C:\Users\park0\github\dataset\train\freshapples  
  
대상경로 폴더에 원본 이미지와 데이터 증식이미지가 섞여 있는데 원본 이미지가 있는 경우 원본 이미지만 남기고 데이터 증식된 이미지를 삭제 하려고해. 그리고 원본 이미지만 남기는 절차를 다음과 같이 진행하려고 해.  
  
절차  
     
1. 현재 폴더의 파일 목록을 csv로 저장한다.  
2. pandas 데이터 프레임에 csv 불러온다.  
3. 원본파일명의 문자열 구성은 "Screen Shot" +"날짜" + "at" +시간 +"PM"으로 구성된다.(확장자 제외)  
   이 이름을 원본파일명이라는 컬럼을 생성해서 데이터프레임에 추가해줘.  
   원본 파일 문자열 앞에 붙는 문자열은 prefix 문자열인데 prefix를 파일명을 suffix로 변경하고 파일명을 수정해주고, 실제 파일명도 변경해줘.  데이터 프레임에 변경된 파일명 컬럼도 추가해줘.  
4. 원본 파일과 증식된 파일을 구별하는 컬럼을 추가하고 원본은 1, 데이터 증식된 파일은 0으로 표기한다. (원본 파일명은 파일명안에 rotated, saltandpepper,translation, vertical_flip과 같은 문자열을 포함하지 않아. 만약 이러한 문자열을 포함하고 있다면 데이터 증식된 파일이다.)  
5. 원본파일이 없고, 데이터 증식 파일만 있는 경우 파일명에 vertical_flip있는 파일이 1순위 대체파일이고 이 파일도 없으면 salt_and_pepper 문자열이 있는 경우 2순위, translation 문자열이 포함된 순으로 대체제 컬럼을 생성하고 1로 체크 한다.  
6. 원본 컬럼에 1이거나, 대체제 컬럼이 1인 파일만 남기고 모두 삭제한다.
```




# Colab Enterprise에서 정제한 이미지 파일들을 통해서 학습을 하기

## 학습(train) 파일을 가져와서 압축 풀기

```python
import gdown
gdown.download(id='1lLNu7W88x93MZALiomWjAGlkitpgkbUa', output='train.zip')
!unzip -qq train.zip
```

```python
!mkdir train
```

```python
!mv freshapples train
!mv freshbanana train
!mv freshoranges train
```

```python
!mv rottenapples/ train
!mv rottenbanana/ train
!mv rottenoranges/ train
```

```python
# prompt: /content/train 경로 아래에 폴더명들을 리스트로 출력해줘
import os
path = '/content/train'
folders = os.listdir(path)
folders
```

출력
```
['rottenoranges',
 'rottenbanana',
 'freshoranges',
 'freshbanana',
 'rottenapples',
 'freshapples']
```

```python
import gdown

gdown.download(id='1lLNu7W88x93MZALiomWjAGlkitpgkbUa', output='train.zip')

!unzip -qq train.zip
```

```python
# prompt: /content/train 경로 아래에 폴더들의 파일의 갯수를 확인해줘
for folder in folders:
  print(f"{folder} count: {len(os.listdir(os.path.join(path, folder)))}")
```

출력
```
rottenoranges count: 222 
rottenbanana count: 306 
freshoranges count: 205 
freshbanana count: 218 
rottenapples count: 326 
freshapples count: 232
```


## train 폴더에서 일부를 valid폴더로 복사해서 데이터셋 분할

```python
# prompt: train의 하위 폴더에 6개 폴더가 있는데 폴더별 전체 데이터 갯수를 확인하고, 갯수의 20%를 /content/valid폴더를 생성하고 동일하게 6개 하위 폴더를 만들어서 각 폴더에 복사하는 코드 생성

import os
import shutil
import random

# train 폴더 경로
train_path = '/content/train'

# valid 폴더 경로
valid_path = '/content/valid'

# valid 폴더 생성
os.makedirs(valid_path, exist_ok=True)

# train 폴더의 하위 폴더들을 순회
for folder_name in os.listdir(train_path):

  # train 하위 폴더 경로
  train_folder_path = os.path.join(train_path, folder_name)

  # valid 하위 폴더 경로
  valid_folder_path = os.path.join(valid_path, folder_name)

  # valid 하위 폴더 생성
  os.makedirs(valid_folder_path, exist_ok=True)

  # 파일 목록 가져오기
  files = os.listdir(train_folder_path)

  # 파일 개수
  num_files = len(files)

  # 20% 계산 (소수점 이하 버림)
  num_valid = int(num_files * 0.2)

  # 랜덤하게 파일 선택
  valid_files = random.sample(files, num_valid)

  # valid 폴더로 파일 복사
  for file_name in valid_files:
    src_path = os.path.join(train_folder_path, file_name)
    dst_path = os.path.join(valid_folder_path, file_name)
    shutil.move(src_path, dst_path)  # move를 사용하여 train에서 valid로 파일 이동

  print(f"{folder_name} train count: {len(os.listdir(train_folder_path))}")
  print(f"{folder_name} valid count: {len(os.listdir(valid_folder_path))}")
```

출력:
```
rottenoranges train count: 178
rottenoranges valid count: 44
rottenbanana train count: 245
rottenbanana valid count: 61
freshoranges train count: 164
freshoranges valid count: 41
freshbanana train count: 175
freshbanana valid count: 43
rottenapples train count: 261
rottenapples valid count: 65
freshapples train count: 186
freshapples valid count: 46
```


```python
IMG_SIZE = 150
BATCH_SIZE = 32
EPOCHS = 30
```


## 모델링 하기

```python
# Keras 3.x 변경사항: keras.utils를 직접 사용
from keras.utils import image_dataset_from_directory

# 이 함수는 fit함수한테 데이터를 공급하는 역할
train_dataset = image_dataset_from_directory(

    # 이미지를 가져올 경로
    "/content/train",
    
    # 이미지 사이즈를 IMG_SIZE,IMG_SIZE으로 변경
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE)

validation_dataset = image_dataset_from_directory(

    "/content/valid",
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE)

  

# predict나 evaluate함수에게 데이터를 전달

# test_dataset = image_dataset_from_directory(
#     "/content/seg_pred/seg_pred",
#     #image_size=(IMG_SIZE, IMG_SIZE),
#     batch_size=BATCH_SIZE)
```

출력:
```
Found 1209 files belonging to 6 classes. 
Found 300 files belonging to 6 classes.
```


```python
for data_batch, labels_batch in train_dataset:
    print("데이터 배치 크기:", data_batch.shape)
    print("레이블 배치 크기:", labels_batch.shape)
    break
```

출력:
```
데이터 배치 크기: (32, 150, 150, 3) 
레이블 배치 크기: (32,)
```

```python
import keras

# Keras 3.x 변경사항: keras.applications.Xception 사용

# Xception모델 가져오기, 분류기를 안가져오기, conv_base의 가중치는 'imagenet'것을 가져오기

conv_base  = keras.applications.Xception(weights="imagenet", include_top=False, input_shape=(IMG_SIZE,IMG_SIZE,3))

conv_base.trainable = False
```

```python
from keras import layers, models

data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.5),
        layers.RandomZoom(0.2),
    ]

)

inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))

x = data_augmentation(inputs)

# Keras 3.x 변경사항: keras.applications.xception.preprocess_input 사용
x = keras.applications.xception.preprocess_input(x)

x = conv_base(x)

x = layers.GlobalAveragePooling2D()(x) # Replace Flatten, Dense, Dropout

outputs = layers.Dense(6, activation="softmax")(x)

model = keras.Model(inputs, outputs)

model.compile(loss="sparse_categorical_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])
```

```python
callbacks = [
    keras.callbacks.ModelCheckpoint(
        filepath="fresh_N_rotten_xception.keras", # Updated filename
        save_best_only=True,
        monitor="val_loss")
]

history = model.fit(
    train_dataset,
    epochs=EPOCHS,
    validation_data=validation_dataset,
    callbacks=callbacks)
```

```python
import matplotlib.pyplot as plt

acc = history.history["accuracy"]
val_acc = history.history["val_accuracy"]
loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, "bo", label="Training accuracy")
plt.plot(epochs, val_acc, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.legend()
plt.figure()
plt.plot(epochs, loss, "bo", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.legend()
plt.show()
```

출력:
![[Pasted image 20250725145116.png]]


## test 데이터셋 가져와서 테스트하기

```python
import gdown

!mkdir test

gdown.download(id='11cpQXpG-Iassd6NAoEaCg8tYKxUKxo08', output='test/test.zip')

%cd test

!unzip -qq test.zip
```



```python
# predict나 evaluate함수에게 데이터를 전달

test_dataset = image_dataset_from_directory(
    "/content/test",
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE)
```

출력:
```
Found 886 files belonging to 6 classes.
```



```python
# prompt: test 데이터셋으로 모델 테스트하기

# Evaluate the model on the test dataset
loss, accuracy = model.evaluate(test_dataset)

print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")
```

출력:
```
Test Loss: 0.0815
Test Accuracy: 0.9763
```



```python
import gdown

!mkdir test

gdown.download(id='11cpQXpG-Iassd6NAoEaCg8tYKxUKxo08', output='test/test.zip')

%cd test

!unzip -qq test.zip
```

```python
# prompt: 위의 결과를 클래스 번호가 아닌 클래스명으로 확인하기
import numpy as np
from sklearn.metrics import accuracy_score

# 클래스 이름 정의 (실제 클래스 이름에 맞게 수정해야 함)
class_names = ['freshapples', 'freshbanana', 'freshoranges', 'rottenapples', 'rottenbanana', 'rottenoranges']

# 각 클래스별 이미지를 저장할 리스트
class_images = [[] for _ in range(6)]
class_labels = [[] for _ in range(6)]

# 테스트 데이터셋에서 이미지와 레이블을 클래스별로 분류
for images, labels in test_dataset:

  for i in range(len(images)):
  
    class_images[labels[i].numpy()].append(images[i].numpy())
    class_labels[labels[i].numpy()].append(labels[i].numpy())

# 클래스별 예측 및 정확도 계산
class_accuracies = []

for i in range(6):

  if len(class_images[i]) > 0:  # 클래스에 이미지가 있는 경우에만 계산
    image_array = np.array(class_images[i])
    predictions = model.predict(image_array)
    predicted_labels = np.argmax(predictions, axis=1)
    true_labels = np.array(class_labels[i])
    accuracy = accuracy_score(true_labels, predicted_labels)
    class_accuracies.append(accuracy)
    print(f"Class {class_names[i]}: {accuracy:.4f}") # 클래스 이름으로 출력

  else:
    print(f"Class {class_names[i]}: No images found.") # 클래스 이름으로 출력

  

# 전체 정확도 계산 (클래스별 이미지 개수를 고려한 가중 평균)
total_images = sum(len(images) for images in class_images)
weighted_accuracy = sum(accuracy * len(images) for accuracy, images in zip(class_accuracies, class_images)) / total_images if total_images else 0

print(f"Weighted Average Accuracy: {weighted_accuracy:.4f}")
```

출력:
```
Class rottenoranges: 0.9242
Weighted Average Accuracy: 0.9763
```


# 내용

1. 테스트 데이터셋을 훈련용 데이터셋과 동일하게 데이터 증식된 이미지를 삭제  
2. 데이터 가져와서 test accuracy 확인하기  
3. 성능 개선점  
   3.1 모델을 정확도가 높은 모델로 변경,  
   3.2 train, valid데이터를 일정하게 비율로 나눴는데 다른기준?  
   3.3 데이터 증식 조건




데이터 변경 -> 예를 들면 img의 사이즈 변경 또는 학습하는 이미지를 정제하지 않고 다 때려박기
150에서 300으로 변경한 후 -> 
Test Loss: 0.0815 Test Accuracy: 0.9763

Test Loss: 0.0738 Test Accuracy: 0.9763
이미지가 너무 많아서 '이미지를 정제하지 않고 다 때려박기' 방법은 안된다.


모델 -> xception말고 다른거로 하고 비교

ResNet50
Test Loss: 1.3328 Test Accuracy: 0.4842
 -> 걍 xception쓰자...

데이터 나누기를 -> 6:4로 해보기
데이터 증식 조건 더 다양하게 하기


