일단 roboflow에 있는 데이터 셋으로 머신러닝을 진행 키로 했음.
https://universe.roboflow.com/project-2rgiq/pet-coqrp

의 958개의 이미지를 통해서 분류

data.yaml에서 'plastic_labels', 'plastic'의 두 가지 클래스로 분류하고 이를 학습을 했음.


train폴더의 이미지
```
전체 개수: 668 

plastic 개수: 311 
plastic_labels 개수: 357 

plastic 비율: 46.56% 
plastic_labels 비율: 53.44%
```
즉, 각 이미지의 비율을 동등하므로 적절하다고 볼 수 있다.


train의 결과
![[Pasted image 20250804152405.png]]

valid의 결과
![[Pasted image 20250804152513.png]]



plastic 클래스는 tarin와 valid에서 mAP50값이 0.983 좋은 정확도를 보이지만 plastic_labels 클래스는 mAP50 값이 0.583으로 좋지 못한 정확도를 보인다.


이미지들의 라벨을 확인해보니 plastic_labels의 좌표값이 부정확하게 찍혀있었다. 따라서 좌표를 정확하게 수정한 뒤에 다시 했다.

before
![[Pasted image 20250804141722.png]]




after
![[Pasted image 20250804144050.png]]




결과

![[Pasted image 20250804155030.png]]

![[Pasted image 20250804155052.png]]

오히려 더 안 좋아짐. -> 기존의 좌표를 조정하지 않음 것으로 학습을 진행.











 plastic 이미지 보다 더 많음에도 불구하고 plastic_labels가 상대적으로 부정확한 이유 ->  라벨은 색상 부터 모양이 매우 다양함. 따라서 보다 다양한 라벨이 붙은 플라스틱 이미지들로 추가 학습을 해야한다.







여기에 더해서 이물질이 있는 패트병을 뜻하는 plastic_foreign_substance 클래스를 data.yaml에 추가한 후 해당 이미지들을 추가했다


그 후 증강을 통해서 좌우 반전、 상하 반전、 30도와 45도 회전 시킨 이미지들을 생성했다。


해당 이미지들의 최종 비율을 다음과 같다。（10 epoch）


![[Pasted image 20250804160417.png]]


（100 epoch）
![[Pasted image 20250804180047.png]]



valid
![[Pasted image 20250804180146.png]]














비닐 

train

![[Pasted image 20250804180749.png]]


valid

![[Pasted image 20250804180912.png]]


일반 비닐에 대한 인식률이 낮음。。。